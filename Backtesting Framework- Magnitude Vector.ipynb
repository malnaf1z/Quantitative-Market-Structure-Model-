{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beef6e7a-fa7d-47a5-8006-69c36ca7b97f",
   "metadata": {},
   "source": [
    "### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92530378-1375-45f1-9412-f07ff329b2e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas_ta as ta\n",
    "import MetaTrader5 as mt5\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.cluster import DBSCAN\n",
    "import random \n",
    "from scipy.stats import norm,t,gamma\n",
    "from scipy.stats import skewnorm\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime, timedelta\n",
    "#### Telegram Configuration\n",
    "\n",
    "import requests\n",
    "import math\n",
    "import inspect\n",
    "\n",
    "# === 1. Initialize MetaTrader 5 ===\n",
    "if not mt5.initialize():\n",
    "    raise RuntimeError(\"MT5 initialization failed. Check terminal connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e436a7-72b0-4062-b9e6-493f98c3c795",
   "metadata": {},
   "source": [
    "### Importing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1066923-b17e-4fc9-82f8-f9fc3ff8367c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def weibull_plot(data):\n",
    "    global x, mu, loc, sigma, skew_pdf, ninety_percentile\n",
    "    if type(data) != np.ndarray:\n",
    "        data = np.array(data)\n",
    "        print(data)\n",
    "    eps = 1e-6\n",
    "    #time_to_tp_long = time_to_tp_long + eps\n",
    "    x = np.linspace(data.min(), data.max(), 200)\n",
    "    mu, loc, sigma  = weibull_min.fit(data)\n",
    "    skew_pdf = weibull_min.pdf(x, mu, loc, sigma)\n",
    "    ninety_percentile = weibull_min.ppf(0.9, mu, loc, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2095fbf8-19aa-48c6-8a52-7990f4841ee0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def gen_trade_id(*size):\n",
    "    #n = size.get(\"size\")\n",
    "    if len(size) == 0:\n",
    "        trade_id = np.random.randint(1000000,9999999)\n",
    "        trade_id = str(\"#\") + str(trade_id)\n",
    "    else:\n",
    "        n = size[0]\n",
    "        trade_id = np.random.randint(1000000,9999999, n)\n",
    "        if n > 1:\n",
    "            idens = []\n",
    "            for iden in trade_id:\n",
    "                #print(iden)\n",
    "                idens.append(str(\"#\") + str(iden))\n",
    "            trade_id = np.array(idens)\n",
    "    return trade_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a4fa5b-179d-4265-b0c1-44668f2d3005",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def normalised_difference(x,y):\n",
    "    try:\n",
    "        \n",
    "        return round(math.log(x/y),7)\n",
    "\n",
    "    except Exception as e:\n",
    "        send_telegram_message(\"MTTF failed to execute due to error in normalised_difference() module!\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50be1af2-5d66-46e4-9ea5-d200618e55aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def risk_reward(a,b,c): # a = sl, b= entry level, c= tp\n",
    "     \n",
    "    try:\n",
    "        return round(abs((c-b)/(b-a)),2)\n",
    "        \n",
    "    except ZeroDivisionError as e:\n",
    "        \n",
    "        send_telegram_message(f\"{e}.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        send_telegram_message(f\"{e}.\")\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f766b937-7f9e-4c46-a463-835ec01f379e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def choose_instrument(x):\n",
    "    global symbol, TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID\n",
    "    \n",
    "    TELEGRAM_BOT_TOKEN = x.get(\"telegram token\")\n",
    "    TELEGRAM_CHAT_ID = x.get(\"telegram chat id\")\n",
    "    symbol= x.get(\"id\")\n",
    "\n",
    "    \n",
    "    return symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3713af45-36b3-4d18-b3d1-b56ae57ff585",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def log_trade(r):\n",
    "\n",
    "    file = f\"{symbol} MTTF Magnitude Vector Backtest Log.csv\"\n",
    "    \n",
    "    if os.path.exists(file):\n",
    "        \n",
    "        if type(r) == pd.core.frame.DataFrame:\n",
    "    \n",
    "            log_row = {\n",
    "                \"Trade id\" : gen_trade_id(),\n",
    "                \"Datetime\" : r[\"timestamp\"].iloc[last_vector_trough] if macro_slope_m5 > 0 else r[\"timestamp\"].iloc[last_vector_peak],\n",
    "                \"Instrument\" : symbol,\n",
    "                \"Session\" : check_session(str(r[\"timestamp\"].iloc[last_vector_peak])) if macro_slope_m5 > 0 else check_session(str(r[\"timestamp\"].iloc[last_vector_peak])) ,\n",
    "                \"Type of Trade\":(\n",
    "                    \"Long\" if macro_slope_m5 > 0 else\n",
    "                    \"Short\" if macro_slope_m5 < 0 else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                \"M5 Trend\": (\n",
    "                    \"Uptrend\" if macro_slope_m5 > 0 else\n",
    "                    \"Downtrend\" if macro_slope_m5 < 0 else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                \"macro_slope_m5\": macro_slope_m5,\n",
    "                \"RSI at peak/trough\" : (\n",
    "                    round((r[\"rsi\"].iloc[last_vector_peak]),2) if macro_slope_m5 < 0 else\n",
    "                    round((r[\"rsi\"].iloc[last_vector_trough]),2) if macro_slope_m5 > 0 else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                \"M5 200 EMA\" : (\n",
    "                    \"Above\" if r[\"close\"].iloc[-1] > r[\"moving average\"].iloc[-1] else\n",
    "                    \"Below\" if r[\"close\"].iloc[-1] < r[\"moving average\"].iloc[-1] else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                \"Peak/Trough Z-Score\" : (\n",
    "                    round((r[\"z_score\"].iloc[last_vector_peak]),2) if macro_slope_m5 < 0 else\n",
    "                    round((r[\"z_score\"].iloc[last_vector_trough]),2) if macro_slope_m5 > 0 else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                          \n",
    "                \"m5 log returns\" : (m5_log_returns if m5_log_returns !=None else \"N/A\") ,\n",
    "                \"m5 peak returns\" : (m5_peak_returns if m5_peak_returns !=None else \"N/A\") ,\n",
    "                \"m5 trough returns\" : (m5_trough_returns if m5_trough_returns !=None else \"N/A\") ,\n",
    "\n",
    "                \"win rr\" : rr,\n",
    "                \"loss rr\" : loss_rr,\n",
    "                \n",
    "                \"Number of Peaks\" : len(valid_peaks_m5),\n",
    "                \"Number of Troughs\" : len(valid_troughs_m5),\n",
    "    \n",
    "                \"m5 ema distance\" : (m5_ema_difference if m5_ema_difference != None else \"N/A\"),\n",
    "                \"m5 peak distance\" : m5_peak_difference  if m5_peak_difference is not None else \"N/A\",\n",
    "                \"m5 trough distance\" : m5_trough_difference if m5_trough_difference is not None else \"N/A\",  \n",
    "                \"Trade Size\" : trade_size if trade_size is not None else 0,\n",
    "                \"std\" : (std / r[\"close\"].iloc[-1]) if std is not None else \"N/A\",\n",
    "                \"atr_std\" : (sdv / r[\"close\"].iloc[-1]) if sdv is not None else \"N/A\",\n",
    "                \"Trade Result\" : (1 if min([tp_idx, sl_idx]) == tp_idx else 0)\n",
    "            }\n",
    "            log = pd.DataFrame([log_row])\n",
    "            data = pd.read_csv(file)\n",
    "            combined = pd.concat([data,log])\n",
    "            combined.to_csv(file, mode = \"w\", index = False)\n",
    "            print(f\"Length of CSV = {len(combined)}\")\n",
    "            print(f\"Trade {log_row.get(\"Trade id\")} Logged!\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if type(r) == pd.core.frame.DataFrame:\n",
    "    \n",
    "            log_row = {\n",
    "                \"Trade id\" : gen_trade_id(),\n",
    "                \"Datetime\" : r[\"timestamp\"].iloc[last_vector_trough] if macro_slope_m5 > 0 else r[\"timestamp\"].iloc[last_vector_peak],\n",
    "                \"Instrument\" : symbol,\n",
    "                \"Session\" : check_session(str(r[\"timestamp\"].iloc[last_vector_peak])) if macro_slope_m5 > 0 else check_session(str(r[\"timestamp\"].iloc[last_vector_peak])),\n",
    "                \"Type of Trade\":(\n",
    "                    \"Long\" if macro_slope_m5 > 0 else\n",
    "                    \"Short\" if macro_slope_m5 < 0 else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                \"M5 Trend\": (\n",
    "                    \"Uptrend\" if macro_slope_m5 > 0 else\n",
    "                    \"Downtrend\" if macro_slope_m5 < 0 else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                \"macro_slope_m5\": macro_slope_m5,\n",
    "\n",
    "                \"RSI at peak/trough\" : (\n",
    "                    round((r[\"rsi\"].iloc[last_vector_peak]),2) if macro_slope_m5 < 0 else\n",
    "                    round((r[\"rsi\"].iloc[last_vector_trough]),2) if macro_slope_m5 > 0 else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                \"M5 200 EMA\" : (\n",
    "                    \"Above\" if r[\"close\"].iloc[-1] > r[\"moving average\"].iloc[-1] else\n",
    "                    \"Below\" if r[\"close\"].iloc[-1] < r[\"moving average\"].iloc[-1] else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                \"Peak/Trough Z-Score\" : (\n",
    "                    round((r[\"z_score\"].iloc[last_vector_peak]),2) if macro_slope_m5 < 0 else\n",
    "                    round((r[\"z_score\"].iloc[last_vector_trough]),2) if macro_slope_m5 > 0 else\n",
    "                    \"N/A\"\n",
    "                ),\n",
    "                          \n",
    "                \"m5 log returns\" : (m5_log_returns if m5_log_returns !=None else \"N/A\") ,\n",
    "                \"m5 peak returns\" : (m5_peak_returns if m5_peak_returns !=None else \"N/A\") ,\n",
    "                \"m5 trough returns\" : (m5_trough_returns if m5_trough_returns !=None else \"N/A\") ,\n",
    "\n",
    "                \"win rr\" : rr,\n",
    "                \"loss rr\" : loss_rr,  \n",
    "\n",
    "                \"Number of Peaks\" : len(valid_peaks_m5),\n",
    "                \"Number of Troughs\" : len(valid_troughs_m5),                \n",
    "    \n",
    "                \"m5 ema distance\" : (m5_ema_difference if m5_ema_difference != None else \"N/A\"),\n",
    "                \"m5 peak distance\" : m5_peak_difference  if m5_peak_difference is not None else \"N/A\",\n",
    "                \"m5 trough distance\" : m5_trough_difference if m5_trough_difference is not None else \"N/A\",  \n",
    "                \n",
    "                \"Trade Size\" : trade_size if trade_size is not None else 0,\n",
    "                \"std\" : (std / r[\"close\"].iloc[-1]) if std is not None else \"N/A\",\n",
    "                \"atr_std\" : (sdv / r[\"close\"].iloc[-1]) if sdv is not None else \"N/A\",\n",
    "                \"Trade Result\" : (1 if min([tp_idx, sl_idx]) == tp_idx else 0)\n",
    "            }\n",
    "            log = pd.DataFrame([log_row]) \n",
    "            log.to_csv(file, mode = \"w\", index = False)\n",
    "            print(f\"Length of CSV = {len(log)}\")\n",
    "            print(f\"Trade {log_row.get(\"Trade id\")} Logged!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7bea807-8383-4c3e-98fb-a60df71a22eb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_timeframe_returns(r, x1, x2):\n",
    "\n",
    "    if type(r) == pd.core.series.Series:\n",
    "        \n",
    "            \n",
    "        y2 = r.iloc[x2]\n",
    "            \n",
    "        y1 = r.iloc[x1]\n",
    "    \n",
    "        m5_log_returns = 100*math.log(y2/y1)\n",
    "        m5_log_returns = round(m5_log_returns,7)\n",
    "    return m5_log_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88fa6268-f68f-4511-9e2c-b4070f16930c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def check_session(x):\n",
    "    format_time = \"%Y-%m-%d %H:%M:%S\"\n",
    "    if type(x) != datetime:\n",
    "        x = datetime.strptime(x, format_time)\n",
    "    if 6 <= x.hour < 15:\n",
    "        return \"ASIAN\"\n",
    "    elif 15 <= x.hour <= 20:\n",
    "        return \"EU\"\n",
    "    else:\n",
    "        return \"US\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7533f8fd-d209-4e8b-a285-d5259b51d5f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_magnitude(x):\n",
    "    if type(x) == pd.core.frame.DataFrame:\n",
    "        \n",
    "        magnitude = []\n",
    "        columns = [\"open\", \"low\", \"high\", \"close\"]\n",
    "        alt_columns = [\"Open\", \"Low\", \"High\", \"Close\"]\n",
    "        col_length = []\n",
    "        for column in columns:\n",
    "            if (column == x.columns).any():\n",
    "                \n",
    "                col_length.append(1)\n",
    "        \n",
    "        if len(col_length) == len(columns):\n",
    "            #print(f\"ALL COLUMNS CONFIRMED\")\n",
    "            open_data = x[\"open\"].values.reshape(-1,1)\n",
    "            high_data = x[\"high\"].values.reshape(-1,1)\n",
    "            low_data = x[\"low\"].values.reshape(-1,1)\n",
    "            close_data = x[\"close\"].values.reshape(-1,1)\n",
    "            \n",
    "            ohlc = np.concatenate([open_data, high_data, low_data, close_data], axis = 1)\n",
    "            magnitude = np.linalg.norm(ohlc, axis = 1).reshape(-1,1)\n",
    "            magnitude = magnitude / close_data\n",
    "    \n",
    "        else:\n",
    "            \n",
    "            for column in alt_columns:\n",
    "                if (column == x.columns).any():\n",
    "                    \n",
    "                    col_length.append(1)\n",
    "            #print(f\"ALL COLUMNS CONFIRMED\")\n",
    "            if len(col_length) == len(alt_columns):\n",
    "                open_data = x[\"Open\"].values.reshape(-1,1)\n",
    "                high_data = x[\"High\"].values.reshape(-1,1)\n",
    "                low_data = x[\"Low\"].values.reshape(-1,1)\n",
    "                close_data = x[\"Close\"].values.reshape(-1,1)\n",
    "                \n",
    "                ohlc = np.concatenate([open_data, high_data, low_data, close_data], axis = 1)\n",
    "                magnitude = np.linalg.norm(ohlc, axis = 1).reshape(-1,1)\n",
    "                magnitude = magnitude / close_data\n",
    "                \n",
    "    return magnitude.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1523bb36-ddf6-4f76-9aa1-68cdc15b82cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def magnitude_vector_peaks(x, **std):\n",
    "    \n",
    "    if type(x) == pd.core.series.Series :\n",
    "        shifted_magnitude = x.shift(1)\n",
    "        \n",
    "    else:\n",
    "        shifted_magnitude = np.array(pd.Series(x).shift(1))\n",
    "        \n",
    "    short = []\n",
    "    m = std.get(\"std\")\n",
    "    if m == None:\n",
    "        m = 1\n",
    "    for i in range(10, len(x)):\n",
    "        if (x[i] > shifted_magnitude[i]) == True:\n",
    "            if (x[i-1] > shifted_magnitude[i-1]) == False:\n",
    "                short.append(i)\n",
    "    shortlisted = []\n",
    "    for idx in short:\n",
    "        if x[idx-1] < x.mean() - m*x.std():\n",
    "            shortlisted.append(idx)\n",
    "    return np.array(shortlisted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "182940dc-2feb-4ca7-b544-83dd345b7a1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def magnitude_vector_troughs(x , **std):\n",
    "    if type(x) == pd.core.series.Series :\n",
    "        shifted_magnitude = x.shift(1)\n",
    "        \n",
    "    else:\n",
    "        shifted_magnitude = np.array(pd.Series(x).shift(1))\n",
    "    \n",
    "    long = []\n",
    "    for i in range(10, len(x)):\n",
    "    \n",
    "        if (x[i] > shifted_magnitude[i]) == False:\n",
    "            if (x[i-1] > shifted_magnitude[i-1]) == True:\n",
    "                long.append(i)\n",
    "                \n",
    "    longlisted = []\n",
    "    m = std.get(\"std\")\n",
    "    if m == None:\n",
    "        m = 1\n",
    "    for idx in long:\n",
    "        if x[idx-1] > x.mean() + m*magnitude.std():\n",
    "            longlisted.append(idx)\n",
    "    return np.array(longlisted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea21794-4ec2-42e1-bc1b-e018f41e1e8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def dec(a,symbol):\n",
    "    if symbol==\"GBPUSD\" or symbol==\"EURUSD\" or symbol==\"AUDUSD\" or symbol==\"USDCAD\" or symbol==\"EURGBP\":\n",
    "        return round(a,4) \n",
    "    elif symbol==\"GBPJPY\" or symbol==\"CL=F\"or symbol==\"USDJPY\" or symbol==\"EURJPY\":\n",
    "        return round(a,3)\n",
    "    else:\n",
    "        return round(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a0b700-6575-4cef-9475-0489c8871c94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def risk_reward(a,b,c): # a = sl, b= entry level, c= tp\n",
    "     \n",
    "    try:\n",
    "        return round(abs((c-b)/(b-a)),2)\n",
    "        \n",
    "    except ZeroDivisionError as e:\n",
    "        \n",
    "        send_telegram_message(f\"{e}.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        send_telegram_message(f\"{e}.\")\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04073996-1f67-4b4d-9b31-d55ff3453ee7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pip(a, symbol):\n",
    "    if symbol==\"GBPUSD\" or symbol==\"EURUSD\" or symbol==\"AUDUSD\" or symbol==\"USDCAD\" or symbol==\"EURGBP\":\n",
    "        return a * 10000\n",
    "    elif symbol==\"GBPJPY\" or symbol==\"CL=F\"or symbol==\"USDJPY\" or symbol==\"EURJPY\":\n",
    "        return a * 100  \n",
    "    elif symbol==\"XAUUSD\" or symbol==\"DX-Y.NYB\" or symbol==\"MSFT\" or symbol== \"BTC-USD\":\n",
    "        return a * 10\n",
    "    else:\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15aab45b-d92c-43cb-bd70-c58e6b84aa37",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def risk_reward(a,b,c): # a = sl, b= entry level, c= tp\n",
    "     \n",
    "    try:\n",
    "        return round(abs((c-b)/(b-a)),2)\n",
    "        \n",
    "    except ZeroDivisionError as e:\n",
    "        \n",
    "        send_telegram_message(f\"{e}.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        send_telegram_message(f\"{e}.\")\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45191594-235d-4565-a7b9-b0909398b498",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_fib(r): ### Fibonacci Function âœ…\n",
    "    global lvl_1,lvl_2,lvl_3,tp1,tp4, entry_lvl, fibo_end, fibo_start\n",
    "    if type(r) == pd.core.frame.DataFrame:\n",
    "            \n",
    "        emer_recom_fib=[]\n",
    "        entry_lvl=None\n",
    "        ## Assuming trough has already been established (Most optimum)\n",
    "        \n",
    "        if macro_slope_m5 < 0:\n",
    "            \n",
    "            if last_peak_idx_m5 < last_trough_idx_m5:\n",
    "                \n",
    "                if len(valid_peaks_m5[-6:-1]) > 0:\n",
    "                       \n",
    "                    for i in range (-6,-1):\n",
    "                        if (r[\"high\"].iloc[valid_peaks_m5[i]] > r[\"trend\"].iloc[last_peak_idx_m5]\n",
    "                        and r[\"high\"].iloc[valid_peaks_m5[i]] > r[\"high\"].iloc[last_peak_idx_m5]\n",
    "                        and (last_peak_idx_m5 - valid_troughs_m5[i]) < 288\n",
    "                        ):\n",
    "                            emer_recom_fib.append(r[\"high\"].iloc[valid_peaks_m5[i]])\n",
    "          \n",
    "                if len(emer_recom_fib) > 0:\n",
    "                    \n",
    "                    fibo_start= dec(max(emer_recom_fib),symbol)\n",
    "    \n",
    "                elif len(emer_recom_fib) == 0:\n",
    "                    \n",
    "                    fibo_start=r[\"high\"].iloc[last_peak_idx_m5] \n",
    "           \n",
    "            # Lowest Low has to be detected from point of last_peak_idx to the point of signal being sent, which would be r[\"low\"].iloc[-1]\n",
    "            \n",
    "                fibo_end=r[\"low\"].iloc[last_trough_idx_m5]\n",
    "            \n",
    "            # Distance\n",
    "                distance= fibo_start-fibo_end\n",
    "                lvl1=0.382*distance\n",
    "                lvl2=0.5*distance\n",
    "                lvl3=0.681*distance\n",
    "                lvl4=1.618*distance\n",
    "                lvl5=2.618*distance\n",
    "            \n",
    "                lvl_1=dec((fibo_start-lvl1),symbol)\n",
    "                lvl_2=dec((fibo_start-lvl2),symbol)\n",
    "                lvl_3=dec((fibo_start-lvl3),symbol)\n",
    "                tp1=dec((fibo_start-lvl4),symbol)\n",
    "                tp4=dec((fibo_start-lvl5),symbol)\n",
    "        \n",
    "            if last_peak_idx_m5 > last_trough_idx_m5:\n",
    "                \n",
    "                ## Assumes trough has not been formed yet\n",
    "                lowest_since_peak=(r[\"low\"].iloc[last_peak_idx_m5:]).idxmin()\n",
    "                \n",
    "            \n",
    "            # Lowest Low has to be detected from point of last_peak_idx to the point of signal being sent, which would be r[\"low\"].iloc[-1]\n",
    "            \n",
    "                if len(valid_peaks_m5[-6:-1]) > 0:\n",
    "                       \n",
    "                    for i in range (-6,-1):\n",
    "                        if (r[\"high\"].iloc[valid_peaks_m5[i]] > r[\"trend\"].iloc[last_peak_idx_m5]\n",
    "                        and r[\"high\"].iloc[valid_peaks_m5[i]] > r[\"high\"].iloc[last_peak_idx_m5]\n",
    "                        and (lowest_since_peak - valid_troughs_m5[i]) < 288\n",
    "                        ):\n",
    "                            emer_recom_fib.append(r[\"high\"].iloc[valid_peaks_m5[i]])\n",
    "          \n",
    "                if len(emer_recom_fib) > 0:\n",
    "                    \n",
    "                    fibo_start= dec(max(emer_recom_fib),symbol)\n",
    "    \n",
    "                elif len(emer_recom_fib) == 0:\n",
    "                    \n",
    "                    fibo_start=r[\"high\"].iloc[last_peak_idx_m5]\n",
    "                    \n",
    "                fibo_end=r[\"low\"].iloc[lowest_since_peak]\n",
    "            \n",
    "            # Distance\n",
    "                distance= fibo_start-fibo_end\n",
    "                lvl1=0.382*distance\n",
    "                lvl2=0.5*distance\n",
    "                lvl3=0.681*distance\n",
    "                lvl4=1.618*distance\n",
    "                lvl5=2.618*distance\n",
    "            \n",
    "                lvl_1=dec((fibo_start-lvl1),symbol)\n",
    "                lvl_2=dec((fibo_start-lvl2),symbol)\n",
    "                lvl_3=dec((fibo_start-lvl3),symbol)\n",
    "                tp1=dec((fibo_start-lvl4),symbol)\n",
    "                tp4=dec((fibo_start-lvl5),symbol)\n",
    "\n",
    "            if lvl_2 is not None:\n",
    "                \n",
    "                if r[\"close\"].iloc[-1] > lvl_2:\n",
    "                    entry_lvl = r[\"close\"].iloc[-1]\n",
    "                else:\n",
    "                    entry_lvl = lvl_2\n",
    "    \n",
    "        if macro_slope_m5 > 0:\n",
    "            \n",
    "            if last_peak_idx_m5 > last_trough_idx_m5:\n",
    "            \n",
    "                if len(valid_troughs_m5[-6:-1]) > 0:\n",
    "                    \n",
    "                    for i in range (-6,-1):\n",
    "                        if (r[\"low\"].iloc[valid_troughs_m5[i]] < r[\"trend\"].iloc[last_trough_idx_m5]\n",
    "                        and r[\"low\"].iloc[valid_troughs_m5[i]] < r[\"low\"].iloc[last_trough_idx_m5]\n",
    "                        and (last_trough_idx_m5 - valid_troughs_m5[i]) < 288\n",
    "                        ):\n",
    "                            emer_recom_fib.append(r[\"low\"].iloc[valid_troughs_m5[i]])\n",
    "                  \n",
    "                if len(emer_recom_fib) > 0:\n",
    "                    len(valid_troughs_m5[-6:-1]) > 0\n",
    "                    fibo_start=dec(min(emer_recom_fib),symbol)\n",
    "    \n",
    "                elif len(emer_recom_fib) == 0:\n",
    "                    \n",
    "                    fibo_start=r[\"low\"].iloc[last_trough_idx_m5]      \n",
    "            \n",
    "            # Lowest Low has to be detected from point of last_peak_idx to the point of signal being sent, which would be r[\"low\"].iloc[-1]\n",
    "            \n",
    "                fibo_end=r[\"high\"].iloc[last_peak_idx_m5]\n",
    "            \n",
    "            # Distance\n",
    "                distance= fibo_end-fibo_start\n",
    "                lvl1=0.382*distance\n",
    "                lvl2=0.5*distance\n",
    "                lvl3=0.681*distance\n",
    "                lvl4=1.618*distance\n",
    "                lvl5=2.618*distance\n",
    "                \n",
    "                ## Fibonacci retracements\n",
    "            \n",
    "                lvl_1=dec((fibo_start+lvl1),symbol)\n",
    "                lvl_2=dec((fibo_start+lvl2),symbol)\n",
    "                lvl_3=dec((fibo_start+lvl3),symbol)\n",
    "                tp1=dec((fibo_start+lvl4),symbol)\n",
    "                tp4=dec((fibo_start+lvl5),symbol)\n",
    "        \n",
    "            if last_trough_idx_m5 > last_peak_idx_m5:\n",
    "                        \n",
    "                highest_since_trough=(r[\"high\"].iloc[last_trough_idx_m5:]).idxmax()\n",
    "    \n",
    "                if len(valid_troughs_m5[-6:-1]) > 0:\n",
    "                    \n",
    "                    for i in range (-6,-1):\n",
    "                        if (r[\"low\"].iloc[valid_troughs_m5[i]] < r[\"trend\"].iloc[last_trough_idx_m5]\n",
    "                        and r[\"low\"].iloc[valid_troughs_m5[i]] < r[\"low\"].iloc[last_trough_idx_m5]\n",
    "                        and (highest_since_trough - valid_troughs_m5[i]) < 288\n",
    "                        ):\n",
    "                            emer_recom_fib.append(r[\"low\"].iloc[valid_troughs_m5[i]])\n",
    "                  \n",
    "                if len(emer_recom_fib) > 0:\n",
    "                    \n",
    "                    fibo_start=dec(min(emer_recom_fib),symbol)\n",
    "    \n",
    "                elif len(emer_recom_fib) == 0:\n",
    "                    \n",
    "                    fibo_start=r[\"low\"].iloc[last_trough_idx_m5]      \n",
    "    \n",
    "                fibo_end=r[\"high\"].iloc[highest_since_trough]\n",
    "            \n",
    "            # Distance\n",
    "                distance= fibo_end-fibo_start\n",
    "                lvl1=0.382*distance\n",
    "                lvl2=0.5*distance\n",
    "                lvl3=0.681*distance\n",
    "                lvl4=1.618*distance\n",
    "                lvl5=2.618*distance\n",
    "                \n",
    "                ## Fibonacci retracements\n",
    "            \n",
    "                lvl_1=dec((fibo_start+lvl1),symbol)\n",
    "                lvl_2=dec((fibo_start+lvl2),symbol)\n",
    "                lvl_3=dec((fibo_start+lvl3),symbol)\n",
    "                tp1=dec((fibo_start+lvl4),symbol)\n",
    "                tp4=dec((fibo_start+lvl5),symbol)\n",
    "\n",
    "            if lvl_2 is not None:\n",
    "                \n",
    "                if r[\"close\"].iloc[-1] < lvl_2:\n",
    "                    entry_lvl = r[\"close\"].iloc[-1]\n",
    "                else:\n",
    "                    entry_lvl = lvl_2\n",
    "    \n",
    "    return lvl_1,lvl_2,lvl_3,tp1,tp4, entry_lvl, fibo_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be8d818e-e158-4106-8792-25990d5e43de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_sl(r): ### In the process (18/08)\n",
    "    ### Completely unbothered by other technicals\n",
    "    global sl, entry_lvl\n",
    "    if type(r) == pd.core.frame.DataFrame:\n",
    "        \n",
    "    \n",
    "        sl=None\n",
    "        #entry_lvl = lvl_2\n",
    "        recom_sl=[]\n",
    "        emer_recom_sl=[]\n",
    "        stop_loss=[]\n",
    "        sl_dist = data[\"atr\"].mean() *5\n",
    "        if entry_lvl is not None:\n",
    "            sl1=dec((entry_lvl+sl_dist),symbol)\n",
    "            stop_loss.append(sl1)\n",
    "        m5atr=(data[\"atr\"]).mean()\n",
    "    \n",
    "        if (last_peak_idx_m5 is not None\n",
    "            and entry_lvl is not None\n",
    "            and last_trough_idx_m5 is not None\n",
    "             ):\n",
    "        ## Most optimum\n",
    "        # Uptrend\n",
    "            if macro_slope_m5 > 0:\n",
    "    \n",
    "            ## Main SL mechanism\n",
    "    \n",
    "                if (data[\"low\"].iloc[valid_troughs_m5[-6:-1]] is not None\n",
    "                and len(valid_troughs_m5[-6:-1])>0 \n",
    "        \n",
    "                   ):\n",
    "                    for i in range(-6,-1):\n",
    "                        if last_trough_idx_m5 - valid_troughs_m5[i] < 288:\n",
    "                            if (data[\"low\"].iloc[valid_troughs_m5[i]]< data[\"lower band\"].iloc[last_trough_idx_m5]\n",
    "                            and ((data[\"low\"].iloc[valid_troughs_m5[i]] < data[\"oversold\"].iloc[last_trough_idx_m5])\n",
    "                            or (data[\"low\"].iloc[valid_troughs_m5[i]] < data[\"lower band\"].iloc[last_trough_idx_m5]\n",
    "                                \n",
    "                                ))):\n",
    "        \n",
    "                                emer_recom_sl.append(data[\"low\"].iloc[valid_troughs_m5[i]] - m5atr)\n",
    "                                \n",
    "                           \n",
    "                            elif data[\"low\"].iloc[valid_troughs_m5[i]]< data[\"low\"].iloc[last_trough_idx_m5]:\n",
    "                                \n",
    "                                recom_sl.append(data[\"low\"].iloc[valid_troughs_m5[i]] - m5atr)\n",
    "                        \n",
    "    \n",
    "                if ( ## Classifier \n",
    "                ((data[\"low\"].iloc[last_trough_idx_m5] < data[\"lower band\"].iloc[last_trough_idx_m5])\n",
    "                or (data[\"close\"].iloc[last_trough_idx_m5] < data[\"lower band\"].iloc[last_trough_idx_m5]))\n",
    "                ):\n",
    "        \n",
    "                    recom_sl.append((data[\"low\"].iloc[last_trough_idx_m5] - m5atr))  \n",
    "                    \n",
    "    \n",
    "                elif ( ## Classifier \n",
    "                    ((r[\"lower midline\"].iloc[last_trough_idx_m5] > r[\"low\"].iloc[last_trough_idx_m5] > r[\"lower band\"].iloc[last_trough_idx_m5])\n",
    "                    or (r[\"lower midline\"].iloc[last_trough_idx_m5] > r[\"close\"].iloc[last_trough_idx_m5] > r[\"lower band\"].iloc[last_trough_idx_m5]))\n",
    "                ):\n",
    "                    recom_sl.append((r[\"lower band\"].iloc[last_trough_idx_m5] - m5atr)) \n",
    "        \n",
    "                  ### Risk On\n",
    "    \n",
    "                if last_peak_idx_m5 > last_trough_idx_m5:\n",
    "    \n",
    "                    if len(r[\"low\"].iloc[-6:-1])>0:      \n",
    "                        max_5_idx = r[\"low\"].iloc[-6:-1].idxmin()\n",
    "                        for i in range(-6,-1):\n",
    "                            if max_5_idx - valid_troughs_m5[i] < 288:\n",
    "                                if (r[\"low\"].iloc[valid_troughs_m5[i]]< r[\"low\"].iloc[max_5_idx]\n",
    "                                and ((r[\"low\"].iloc[valid_troughs_m5[i]] < r[\"oversold\"].iloc[max_5_idx])\n",
    "                                or (r[\"close\"].iloc[valid_troughs_m5[i]] < r[\"oversold\"].iloc[max_5_idx]\n",
    "                                    \n",
    "                                    ))):\n",
    "                                    \n",
    "                                    emer_recom_sl.append(r[\"low\"].iloc[valid_troughs_m5[i]] - m5atr)\n",
    "                                    \n",
    "                                elif r[\"low\"].iloc[valid_troughs_m5[i]]< r[\"low\"].iloc[max_5_idx]:\n",
    "                                    \n",
    "                                    recom_sl.append(r[\"low\"].iloc[valid_troughs_m5[i]] - m5atr)\n",
    "    \n",
    "                        if len(emer_recom_sl) ==0 and len(recom_sl) ==0: ## Backup\n",
    "                                            \n",
    "                            for i in range(-6,-1):\n",
    "        \n",
    "                                    if (r[\"low\"].iloc[valid_troughs_m5[i]]< r[\"low\"].iloc[max_5_idx]\n",
    "                                    and ((r[\"low\"].iloc[valid_troughs_m5[i]] < r[\"oversold\"].iloc[max_5_idx])\n",
    "                                    or (r[\"close\"].iloc[valid_troughs_m5[i]] < r[\"oversold\"].iloc[max_5_idx]\n",
    "                                        \n",
    "                                        ))):\n",
    "                                        \n",
    "                                        emer_recom_sl.append(r[\"low\"].iloc[valid_troughs_m5[i]] - m5atr)\n",
    "                                        \n",
    "                                    elif r[\"low\"].iloc[valid_troughs_m5[i]]< r[\"low\"].iloc[max_5_idx]:\n",
    "                                        \n",
    "                                        recom_sl.append(r[\"low\"].iloc[valid_troughs_m5[i]] - m5atr)\n",
    "    \n",
    "                ## vector sl\n",
    "                if r[\"low\"].iloc[last_trough_idx_m5] > r[\"low\"].iloc[last_vector_trough]:\n",
    "                    emer_recom_sl.append(r[\"lower band\"].iloc[last_vector_trough] - m5atr)\n",
    "                ###\n",
    "                \n",
    "                if sl==None:\n",
    "                    sl=recom_sl.append((r[\"low\"].iloc[last_trough_idx_m5] - m5atr))\n",
    "                \n",
    "                # because uptrend, 2nd rated SLs should be MIN, and 1st rated SLs should be MAX\n",
    "                \n",
    "    \n",
    "                if (len(recom_sl) > 0) and (len(emer_recom_sl) > 0) :\n",
    "                    sl1=dec(min(emer_recom_sl),symbol)\n",
    "                    sl2=dec(min(recom_sl),symbol)\n",
    "                    if sl2 < sl1:\n",
    "                        sl=sl2\n",
    "                    else:\n",
    "                        sl=sl1\n",
    "    \n",
    "                elif len(emer_recom_sl) > 0:\n",
    "                    sl1=dec(min(emer_recom_sl),symbol)\n",
    "                    \n",
    "                elif len(emer_recom_sl) == 0 and len(recom_sl)>0:\n",
    "                    \n",
    "                    sl=dec(min(recom_sl),symbol)      \n",
    "    \n",
    "                if fibo_start != None:\n",
    "                    \n",
    "                    if sl > entry_lvl:\n",
    "                        \n",
    "                        sl = dec((fibo_start - m5atr), symbol)\n",
    "    \n",
    "        ## Downtrend ##\n",
    "                \n",
    "            if macro_slope_m5 < 0 :\n",
    "    \n",
    "            ## Main SL mechanism\n",
    "                m5atr=(r[\"atr\"].mean())\n",
    "                vital_highs=[]\n",
    "                if (r[\"high\"].iloc[valid_peaks_m5[-6:-1]] is not None\n",
    "                and len(valid_peaks_m5[-6:-1])>0\n",
    "    \n",
    "                   ):\n",
    "                    for i in range(-6,-1):\n",
    "                        if last_peak_idx_m5 - valid_peaks_m5[i] < 288:\n",
    "                            if (r[\"high\"].iloc[valid_peaks_m5[i]]> r[\"high\"].iloc[last_peak_idx_m5]\n",
    "                            and ((r[\"high\"].iloc[i] > r[\"overbought\"].iloc[last_peak_idx_m5])\n",
    "                            or (r[\"high\"].iloc[i] > r[\"upper band\"].iloc[last_peak_idx_m5]\n",
    "                                \n",
    "                                ))):\n",
    "                                \n",
    "                                emer_recom_sl.append(r[\"high\"].iloc[valid_peaks_m5[i]] + m5atr)\n",
    "                                                            \n",
    "                            elif r[\"high\"].iloc[valid_peaks_m5[i]]> r[\"high\"].iloc[last_peak_idx_m5]:\n",
    "                                \n",
    "                                recom_sl.append(r[\"high\"].iloc[valid_peaks_m5[i]] + m5atr)\n",
    "                               \n",
    "                \n",
    "                if ( ## Classifier \n",
    "                ((r[\"high\"].iloc[last_peak_idx_m5] > r[\"upper band\"].iloc[last_peak_idx_m5])\n",
    "                or (r[\"close\"].iloc[last_peak_idx_m5] > r[\"upper band\"].iloc[last_peak_idx_m5]))\n",
    "                ):\n",
    "                    recom_sl.append((r[\"high\"].iloc[last_peak_idx_m5] + m5atr))  \n",
    "                                          \n",
    "                elif ( ## Classifier \n",
    "                    ((r[\"upper midline\"].iloc[last_peak_idx_m5] < r[\"high\"].iloc[last_peak_idx_m5] < r[\"upper band\"].iloc[last_peak_idx_m5])\n",
    "                    or (r[\"upper midline\"].iloc[last_peak_idx_m5] < r[\"close\"].iloc[last_peak_idx_m5] < r[\"upper band\"].iloc[last_peak_idx_m5]))\n",
    "                ):\n",
    "                    recom_sl.append((r[\"upper band\"].iloc[last_peak_idx_m5] + m5atr))\n",
    "    \n",
    "                if last_trough_idx_m5 > last_peak_idx_m5:\n",
    "    \n",
    "            ### Risk On\n",
    "                    if len(r[\"high\"].iloc[-6:-1])> 0:      \n",
    "                        max_5_idx = r[\"high\"].iloc[-6:-1].idxmax()\n",
    "                        for i in range(-6,-1):\n",
    "                            if max_5_idx - valid_peaks_m5[i] < 288:\n",
    "                                if (r[\"high\"].iloc[valid_peaks_m5[i]]> r[\"high\"].iloc[max_5_idx]\n",
    "                                and ((r[\"high\"].iloc[valid_peaks_m5[i]] > r[\"overbought\"].iloc[max_5_idx])\n",
    "                                or (r[\"close\"].iloc[valid_peaks_m5[i]] > r[\"overbought\"].iloc[max_5_idx]\n",
    "                                    \n",
    "                                    ))):\n",
    "                                    emer_recom_sl.append(r[\"high\"].iloc[valid_peaks_m5[i]] + m5atr)\n",
    "                                    \n",
    "                                elif r[\"high\"].iloc[valid_peaks_m5[i]]> r[\"high\"].iloc[max_5_idx]:\n",
    "                                    recom_sl.append(r[\"high\"].iloc[valid_peaks_m5[i]] + m5atr)\n",
    "    \n",
    "                        if len(emer_recom_sl)==0 and len(recom_sl) ==0:\n",
    "                        \n",
    "                            for i in range(-6,-1):\n",
    "                                \n",
    "                                if (r[\"high\"].iloc[valid_peaks_m5[i]]> r[\"high\"].iloc[max_5_idx]\n",
    "                                and ((r[\"high\"].iloc[valid_peaks_m5[i]] > r[\"overbought\"].iloc[max_5_idx])\n",
    "                                or (r[\"close\"].iloc[valid_peaks_m5[i]] > r[\"overbought\"].iloc[max_5_idx]\n",
    "                                    \n",
    "                                    ))):\n",
    "                                    emer_recom_sl.append(r[\"high\"].iloc[valid_peaks_m5[i]] + m5atr)\n",
    "                                    \n",
    "                                elif r[\"high\"].iloc[valid_peaks_m5[i]]> r[\"high\"].iloc[max_5_idx]:\n",
    "                                    \n",
    "                                    recom_sl.append(r[\"high\"].iloc[valid_peaks_m5[i]] + m5atr)                        \n",
    "                                    \n",
    "            \n",
    "                if sl==None:\n",
    "                    \n",
    "                    recom_sl.append((r[\"high\"].iloc[last_peak_idx_m5] + m5atr))\n",
    "\n",
    "                ## vector sl\n",
    "                if r[\"high\"].iloc[last_peak_idx_m5] < r[\"high\"].iloc[last_vector_peak]:\n",
    "                    emer_recom_sl.append(r[\"lower band\"].iloc[last_vector_peak] + m5atr)\n",
    "                ###\n",
    "    \n",
    "                # because downtrend, sl computed should be at MAX for 2nd rated SLs, and MIN for 1st rated SLs\n",
    "                if (len(recom_sl) > 0) and (len(emer_recom_sl) > 0) :\n",
    "                    sl1=dec(max(emer_recom_sl),symbol)\n",
    "                    sl2=dec(max(recom_sl),symbol)\n",
    "                    if sl1 < sl2:\n",
    "                        sl=sl2\n",
    "                    else:\n",
    "                        sl=sl1             \n",
    "                elif len(emer_recom_sl) > 0:\n",
    "                    sl=dec(max(emer_recom_sl),symbol)\n",
    "                    \n",
    "                elif len(emer_recom_sl) == 0 and len(recom_sl)>0 :            \n",
    "                    sl=dec(max(recom_sl),symbol) \n",
    "    \n",
    "                ### Check if sl < entry_lvl\n",
    "                if fibo_start != None:\n",
    "                    \n",
    "                    if sl < entry_lvl:\n",
    "                        \n",
    "                        sl = dec((fibo_start + m5atr), symbol)\n",
    "                \n",
    "    if sl is not None:\n",
    "        return emer_recom_sl, recom_sl, sl\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee74e2a6-dce5-44e0-b3e9-b39660c1ac33",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_tp(r): ## Defining tp, we need to establish values for fibo up or fibo down first\n",
    "    ## Assuming fibo_up() only runs upon the cond. of macro_slope_m5 > 0,\n",
    "    global tp, rr\n",
    "    if type(r) == pd.core.frame.DataFrame:\n",
    "        \n",
    "    \n",
    "        if macro_slope_m5 > 0:\n",
    "            tp_list=[]\n",
    "            tp_recom=[]\n",
    "            tp_norm=[]\n",
    "            if tp1 is not None:\n",
    "                tp_list.append(tp1)\n",
    "    \n",
    "            try :\n",
    "                \n",
    "                if len(jeblon)> 0:\n",
    "                    for val in jeblon:\n",
    "                        if val > r[\"upper midline\"].iloc[last_trough_idx_m5]:\n",
    "                            tp_list.append(val)\n",
    "    \n",
    "            except NameError:\n",
    "                pass\n",
    "                \n",
    "            if r[\"high\"].iloc[last_peak_idx_m5] > r[\"upper midline\"].iloc[last_peak_idx_m5]:\n",
    "                tp_list.append(r[\"high\"].iloc[last_peak_idx_m5] + m5atr)\n",
    "            if tp4 is not None:\n",
    "                if tp4 <= r[\"upper band\"].iloc[last_trough_idx_m5]:\n",
    "                    tp_list.append(tp4)\n",
    "            \n",
    "            ### Risk reward bigger than 1.0\n",
    "            \n",
    "            for tp in tp_list:\n",
    "                \n",
    "                try :\n",
    "                    \n",
    "                    rr=risk_reward(sl,entry_lvl,tp)\n",
    "                    if rr > 1.0:\n",
    "                        tp_recom.append(tp)\n",
    "                    else:\n",
    "                        tp_norm.append(tp)\n",
    "                        \n",
    "                    if len(tp_recom) > 0:\n",
    "                        \n",
    "                        tp=dec(min(tp_recom),symbol)\n",
    "                        rr = risk_reward(sl,entry_lvl,tp)\n",
    "                        rr = round(rr,2)\n",
    "                        \n",
    "                    elif tp_recom==0 and len(tp_norm)>0:\n",
    "                        \n",
    "                        tp=dec(max(tp_norm),symbol)\n",
    "                        rr = risk_reward(sl,entry_lvl,tp)\n",
    "                        rr = round(rr,2)\n",
    "    \n",
    "                except ZeroDivisionError as e :\n",
    "                    \n",
    "                    rr = 0.0\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    rr= 0.0\n",
    "        \n",
    "                if rr < 1.0:\n",
    "                    \n",
    "                    try:\n",
    "                        \n",
    "                        tp = dec((lvl_2+(lvl_2-sl)),symbol)\n",
    "                        ## reassign rr\n",
    "                        rr=risk_reward(sl,lvl_2,tp)\n",
    "    \n",
    "                    except ZeroDivisionError as e: \n",
    "                        rr = 0.0\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        rr = 0.0\n",
    "                        \n",
    "            \n",
    "        if macro_slope_m5 < 0:\n",
    "            \n",
    "            tp_list=[]\n",
    "            tp_recom=[]\n",
    "            tp_norm=[]\n",
    "            if tp1 is not None:\n",
    "                tp_list.append(tp1)\n",
    "    \n",
    "            try :\n",
    "                if len(jeblon)> 0:\n",
    "                    for val in jeblon:\n",
    "                        if val < r[\"lower midline\"].iloc[last_peak_idx_m5]:\n",
    "                            tp_list.append(val)\n",
    "    \n",
    "            except NameError:\n",
    "                pass\n",
    "                \n",
    "            if r[\"low\"].iloc[last_trough_idx_m5] < r[\"lower midline\"].iloc[last_trough_idx_m5]:\n",
    "                tp_list.append(r[\"high\"].iloc[last_trough_idx_m5] - m5atr)\n",
    "            if tp4 is not None:\n",
    "                if tp4 >= r[\"lower band\"].iloc[last_peak_idx_m5]:\n",
    "                    tp_list.append(tp4)\n",
    "            \n",
    "            ### Risk reward bigger than 1.0\n",
    "            \n",
    "            for tp in tp_list:\n",
    "    \n",
    "                try : \n",
    "                    \n",
    "                    rr=risk_reward(sl,entry_lvl,tp)\n",
    "                    if rr > 1.0:\n",
    "                        tp_recom.append(tp)\n",
    "                    else:\n",
    "                        tp_norm.append(tp)\n",
    "                        \n",
    "                    if len(tp_recom) > 0 :\n",
    "                        \n",
    "                        tp=dec(max(tp_recom),symbol)\n",
    "                        rr = risk_reward(sl,entry_lvl,tp)\n",
    "                        rr = round(rr,2)\n",
    "                        \n",
    "                    elif len(tp_recom)==0 and len(tp_norm)>0 :\n",
    "                        \n",
    "                        tp=dec(min(tp_norm),symbol)\n",
    "                        rr = risk_reward(sl,entry_lvl,tp)\n",
    "                        rr = round(rr,2)\n",
    "    \n",
    "                except ZeroDivisionError as e:\n",
    "                    rr = 0.0\n",
    "    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    rr = 0.0\n",
    "                    \n",
    "            if rr < 1.0: ## establish new rr\n",
    "                \n",
    "                try:\n",
    "                    \n",
    "                    tp=dec((lvl_2-(sl-lvl_2)),symbol)\n",
    "                    rr=risk_reward(sl,lvl_2,tp)\n",
    "    \n",
    "                except ZeroDivisionError as e:\n",
    "                    rr = 0.0\n",
    "                except Exception as e:\n",
    "                    rr = 0.0\n",
    "    \n",
    "    if tp is not None :\n",
    "        return tp, tp_recom, tp_norm\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d4b7bea-2e3e-42d7-9341-c72bfd9fca98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_dummy_regression(x,y):\n",
    "    global test_trend, test_upper_band, test_lower_band, test_slope\n",
    "    x_model= x.values.reshape(-1,1)\n",
    "    y_model= y.values\n",
    "    \n",
    "    lig_model=LinearRegression().fit(x_model,y_model)\n",
    "    test_trend=lig_model.predict(x_model)\n",
    "    test_slope=lig_model.coef_[0]\n",
    "\n",
    "    \n",
    "    test_residuals = y_model - test_trend \n",
    "    test_std = test_residuals.std()\n",
    "    \n",
    "\n",
    "    test_upper_band =test_trend + 2*test_std\n",
    "    test_lower_band = test_trend - 2*test_std\n",
    "\n",
    "    return test_trend, test_upper_band, test_lower_band, test_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3069089-e96c-4293-a989-865980ea505a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def conservative_tp():\n",
    "    global csv_tp\n",
    "    if macro_slope_m5 > 0:\n",
    "        \n",
    "        csv_tp = entry_lvl + (entry_lvl - sl)\n",
    "        csv_tp = dec(csv_tp,symbol)\n",
    "        \n",
    "    if macro_slope_m5 < 0:\n",
    "        \n",
    "        csv_tp = entry_lvl - (sl - entry_lvl)\n",
    "        csv_tp = dec(csv_tp,symbol)\n",
    "\n",
    "    return csv_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15fc1e89-faf2-48b3-b6dd-ce137d5c6231",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def change_timezone(x):\n",
    "\n",
    "    format_df = \"%Y-%m-%d %H:%M:%S%z\"\n",
    "    new_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    x = datetime.strptime(x, format_df).astimezone()     \n",
    "    x = datetime.strftime(x, new_format)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f6a8b-8f73-46f3-a768-b1b0bf8b7e3d",
   "metadata": {},
   "source": [
    "### Instrument List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d26ace1-841a-4240-b69d-03b8f5ba13a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "eu = {\"id\": \"EURUSD\",\n",
    "      \"telegram token\" : \"7655061560:AAF3ZhFIw1fDopS3Ubiq4d3BZC31vU9JQDM\",\n",
    "      \"telegram chat id\" : \"-1002994239464\"\n",
    "    }\n",
    "\n",
    "gu = {\"id\": \"GBPUSD\",\n",
    "      \"telegram token\" : \"7726925813:AAEVeGL3WqAHG3EWIpCEbPAt9cmzKUHkl4E\",\n",
    "      \"telegram chat id\" : \"-1002689119862\"\n",
    "    }\n",
    "gj = {\"id\": \"GBPJPY\",\n",
    "      \"telegram token\" : \"7724186584:AAH0IF168B0IIB3TG7VDk-XJr0S1hZB1ofk\",\n",
    "      \"telegram chat id\" : \"-1003096573575\"\n",
    "    }\n",
    "gold = {\"id\": \"XAUUSD\",\n",
    "      \"telegram token\" : \"7739329449:AAHtbnTQl1rM2z0G6LHXtSRETKxXz8V3NJM\",\n",
    "      \"telegram chat id\" : \"-1003060664508\"\n",
    "    }\n",
    "dow = {\"id\": \"US30.cash\",\n",
    "      \"telegram token\" : \"8090148960:AAEVim7HD9dIz6KZqP6jI2gkpFGbZDk6q7A\",\n",
    "      \"telegram chat id\" : \"-1003044860973\"\n",
    "    }\n",
    "dax = {\"id\": \"GER40.cash\",\n",
    "      \"telegram token\" : \"7814087673:AAE9zcAxk9Yio3MmmrC8VESDb1rkxEIdB-o\",\n",
    "      \"telegram chat id\" : \"-1002934706394\"\n",
    "    }\n",
    "uj = {\"id\": \"USDJPY\",\n",
    "      \"telegram token\" : \"7590221480:AAENzVa_IxQ23soCRYPebkPcPBLRtjRCL3w\",\n",
    "      \"telegram chat id\" : \"-1003050413624\"\n",
    "    }\n",
    "ej = {\"id\": \"EURJPY\",\n",
    "      \"telegram token\" : \"7997307038:AAGTk6xSqzJXQnNgprUdyA2P6yEgW0hatm4\",\n",
    "      \"telegram chat id\" : \"-1003001392228\"\n",
    "    }\n",
    "au = {\"id\": \"AUDUSD\",\n",
    "      \"telegram token\" : \"7968282303:AAFaraUeBUmDuD_msQe2AAZl31S3LdHxoYo\",\n",
    "      \"telegram chat id\" : \"-1003095401611\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3197f2a-9f6f-4762-b1b0-7d0b6eb421ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "instrument_list = [gu, gj, eu, ej, au, dow, gold, dax, uj]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b611c-563f-43bf-ae62-341401137391",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab859f-b69f-429e-babc-6fdb92fb8c55",
   "metadata": {},
   "source": [
    "1. Range must be defined, starting index must be at 2000, ends at 48000,\n",
    "   - so for example, for each candle, (2000, 4000), (2001, 4001), (2002, 4002)\n",
    "2. 19:09 - Template for calculating regression slopes completed\n",
    "3. TBC - 07/12 onwards\n",
    "   - import compute_sl(), compute_fib(), compute_tp() functions\n",
    "   - Calc. Max Price deviation from signal price\n",
    "   - Emulate csv logging features in template\n",
    "   - Run for all symbols\n",
    "   \n",
    "4. Ammended sl logic for vector indicator, might need fine tuning, basic sl implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161bbe53-a5ee-4e5f-b093-da80b7bddfa3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Backtest Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2580aabe-132d-4afe-8c18-4e91c5512fc0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m symbol \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEURUSD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m M5 DATA 2018-NOW.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     17\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(change_timezone)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#### For all instruments\n",
    "total_cum = []\n",
    "total_short_sl = []\n",
    "total_short_tp = []\n",
    "\n",
    "total_long_tp = []\n",
    "total_long_sl = []\n",
    "signal_delay=[]\n",
    "\n",
    "symbol = \"EURUSD\"\n",
    "\n",
    "file = f\"{symbol} M5 DATA 2018-NOW.csv\"\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "if \"timestamp\" in df.columns:\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(change_timezone)\n",
    "    print(\"Timezone changed\")\n",
    "\n",
    "\n",
    "df[\"rsi\"] = ta.rsi(df[\"close\"], length=14)\n",
    "df[\"moving average\"] = df[\"close\"].rolling(window = 200).mean()\n",
    "\n",
    "init_bar = 4000\n",
    "fin_bar = len(df)\n",
    "bars = len(df)\n",
    "progress = np.linspace(init_bar, bars, 11)\n",
    "all_slopes = []\n",
    "shorts = []\n",
    "close_shorts = []\n",
    "longs = []\n",
    "close_longs = []\n",
    "entry_hit = []\n",
    "\n",
    "short_tp_hit = []\n",
    "short_sl_hit = []\n",
    "\n",
    "long_tp_hit = []\n",
    "long_sl_hit = []\n",
    "cum= []\n",
    "\n",
    "for idx in range(init_bar, fin_bar, 1):\n",
    "## 1. Establish dataframe taken\n",
    "\n",
    "    data = df.iloc[idx - 2000:idx].copy()\n",
    "    data = data.reset_index(drop=True)\n",
    "    numbers = np.arange(0,len(data))\n",
    "    numbers = pd.Series(numbers)\n",
    "\n",
    "    ### Calculating MAGNITUDE VECTORS\n",
    "    magnitude = calculate_magnitude(data)\n",
    "    \n",
    "    vector_peaks = magnitude_vector_peaks(magnitude, std  = 1.5)\n",
    "    vector_troughs = magnitude_vector_troughs(magnitude, std  = 1.5)\n",
    "    \n",
    "    if len(vector_peaks) > 0 and len(vector_troughs) > 0:\n",
    "        \n",
    "        last_vector_peak = vector_peaks[-1]\n",
    "        last_vector_trough = vector_troughs[-1]\n",
    "\n",
    "    ## 2. Generate slope regression for each individual slice of data\n",
    "    test = generate_dummy_regression(numbers, data[\"close\"])\n",
    "    trend = test[0]\n",
    "    data[\"trend\"] = trend\n",
    "    upper_band = test[1]\n",
    "    lower_band = test[2]\n",
    "    data[\"upper midline\"] = (test[1] + test[0])/2\n",
    "    data[\"lower midline\"] = (test[2] + test[0])/2#+ lower_band\n",
    "    \n",
    "    data[\"overbought\"] = (data[\"upper midline\"] + upper_band)/2\n",
    "    overbought = data[\"overbought\"].values\n",
    "    \n",
    "    data[\"oversold\"] = (data[\"lower midline\"] + lower_band)/2\n",
    "    oversold = data[\"oversold\"].values\n",
    "    \n",
    "    data[\"upper band\"] = upper_band\n",
    "    data[\"lower band\"] = lower_band\n",
    "    macro_slope_m5 = test[3]\n",
    "\n",
    "    data[\"atr\"] = ta.atr(high = data[\"high\"], low= data[\"low\"], close = data[\"close\"], length = 14)\n",
    "    m5atr = data[\"atr\"].mean() \n",
    "    sdv= data[\"atr\"].std() \n",
    "    data[\"z_score\"]=(data[\"atr\"]-data[\"atr\"].mean())/sdv\n",
    "\n",
    "    std = data[\"close\"].std() \n",
    "\n",
    "    ## 3. Generate peaks/ troughs with find_peaks()\n",
    "    const = 0.5\n",
    "    peaks, _ = find_peaks(data[\"close\"], prominence = const*data[\"close\"].std(), distance = 3)\n",
    "    troughs, _ = find_peaks(-data[\"close\"], prominence = const*data[\"close\"].std(), distance = 3)\n",
    "    valid_peaks_m5 = peaks\n",
    "    valid_troughs_m5 = troughs\n",
    "  \n",
    "    if len(valid_peaks_m5) < 10 and len(valid_troughs_m5) < 10:\n",
    "        const = 0.5*0.5\n",
    "        peaks, _ = find_peaks(data[\"close\"], prominence = const*data[\"close\"].std(), distance = 3)\n",
    "        troughs, _ = find_peaks(-data[\"close\"], prominence = const*data[\"close\"].std(), distance = 3)\n",
    "        valid_peaks_m5 = peaks\n",
    "        valid_troughs_m5 = troughs\n",
    "        \n",
    "        if len(valid_peaks_m5) < 10 and len(valid_troughs_m5) < 10:\n",
    "            const = 0.5*0.5*0.5\n",
    "            peaks, _ = find_peaks(data[\"close\"], prominence = const*data[\"close\"].std(), distance = 3)\n",
    "            troughs, _ = find_peaks(-data[\"close\"], prominence = const*data[\"close\"].std(), distance = 3)\n",
    "            valid_peaks_m5 = peaks\n",
    "            valid_troughs_m5 = troughs\n",
    "\n",
    "### TBA\n",
    "\n",
    "        \n",
    "    last_peak_idx_m5 = peaks[-1]\n",
    "    last_trough_idx_m5 = troughs[-1]      \n",
    "\n",
    "    ## generate linear regression for peaks and troughs\n",
    "    numbers = np.arange(len(data)).reshape(-1,1)\n",
    "    x = valid_peaks_m5.reshape(-1,1)\n",
    "    y = data[\"high\"].iloc[valid_peaks_m5]\n",
    "    model = LinearRegression().fit(x,y)\n",
    "    peak_trend = model.predict(numbers)\n",
    "    data[\"peak trend\"] = peak_trend\n",
    "    \n",
    "    x = valid_troughs_m5.reshape(-1,1)\n",
    "    y = data[\"low\"].iloc[valid_troughs_m5]\n",
    "    model = LinearRegression().fit(x,y)\n",
    "    trough_trend = model.predict(numbers)   \n",
    "    data[\"trough trend\"] = trough_trend\n",
    "\n",
    "    numbers = np.arange(len(data))\n",
    "\n",
    "    ## establishing logic\n",
    "    \n",
    "    if macro_slope_m5 < 0:\n",
    "        \n",
    "        if upper_band[last_vector_peak] >= data[\"high\"].iloc[last_vector_peak] >= overbought[last_vector_peak]:\n",
    "            \n",
    "            if shorts == []:\n",
    "\n",
    "                ## Trade metrics\n",
    "                compute_fib(data)\n",
    "                print(f\"Entry lvl is {entry_lvl}\")\n",
    "                compute_sl(data)\n",
    "                compute_tp(data)\n",
    "                tp = conservative_tp()\n",
    "\n",
    "                ### Establish risk reward, regardless of hit entry or not, assume market order\n",
    "\n",
    "                rr = risk_reward(sl, data[\"close\"].iloc[-1],tp)\n",
    "\n",
    "                if rr > 0.8:\n",
    "                    \n",
    "                \n",
    "                    if rr < 1:\n",
    "                        loss_rr = 2-rr\n",
    "                    else:\n",
    "                        loss_rr = 1\n",
    "                    \n",
    "                    if data[\"close\"].iloc[-1] < sl:\n",
    "                        \n",
    "                        \n",
    "                        ## global df\n",
    "                        ## for tp,\n",
    "                        df_idx = (idx + last_vector_peak) - 2000\n",
    "        \n",
    "                        if df_idx < bars - 2000:\n",
    "    \n",
    "                            print(f\"RR = {rr}\") if rr is not None else print(\"RR failed to be computed\")\n",
    "                            print(f\"Loss RR = {-loss_rr}\") if loss_rr is not None else print(\"Loss RR failed to be computed\")\n",
    "\n",
    "                            print(f\"sl == {sl}\") if entry_lvl != None else print(\"None\")\n",
    "                            print(f\"entry = {entry_lvl}\") if entry_lvl != None else print(\"None\")\n",
    "                            print(f\"tp == {tp}\") if tp != None else print(\"None\")                     \n",
    "                            \n",
    "                        \n",
    "                            for index, val in enumerate(df[\"close\"].iloc[df_idx:] < tp):\n",
    "                                if index < 2000:\n",
    "                                    \n",
    "                                    if val == True:\n",
    "                                        tp_idx = index\n",
    "                                        break\n",
    "\n",
    "                                else:\n",
    "                                    tp_idx = 9999\n",
    "                                    \n",
    "                            for index, val in enumerate(df[\"close\"].iloc[df_idx:] > sl):\n",
    "                                \n",
    "                                if index < 2000:\n",
    "                                    \n",
    "                                    if val == True:\n",
    "                                        sl_idx = index\n",
    "                                        break\n",
    "\n",
    "                                else:\n",
    "                                    sl_idx = 9999\n",
    "\n",
    "                            if sl_idx != tp_idx:\n",
    "                                \n",
    "                                    \n",
    "                                if sl_idx  != None and tp_idx != None:\n",
    "                                    print(f\"sl_idx = {sl_idx}, tp_idx = {tp_idx}\")\n",
    "                                    \n",
    "                                    if min([tp_idx, sl_idx]) == sl_idx:\n",
    "                                        short_sl_hit.append(sl_idx)\n",
    "                                        total_short_sl.append(sl_idx)\n",
    "                                        cum.append(loss_rr*-1)\n",
    "                                        total_cum.append(loss_rr*-1)\n",
    "                                        \n",
    "                                        print(\"SL Hit!\")\n",
    "                                    elif min([tp_idx, sl_idx]) == tp_idx:\n",
    "                                        short_tp_hit.append(tp_idx)\n",
    "                                        total_short_tp.append(tp_idx)\n",
    "                                        total_cum.append(rr*1)\n",
    "                                        cum.append(rr*1)\n",
    "                                        print(\"TP Hit!\")\n",
    "                                    \n",
    "                                if data[\"close\"].iloc[-1] == entry_lvl:\n",
    "                                    entry_hit.append(1)\n",
    "                                if data[\"close\"].iloc[-1] < entry_lvl:\n",
    "                                    for index, boolean in data[\"close\"].iloc[df_idx:] > entry_lvl:\n",
    "                                        \n",
    "                                        if index < 2000:\n",
    "                                            \n",
    "                                            if boolean == True:\n",
    "                                                if min([tp_idx, sl_idx]) == tp_idx:\n",
    "                                                    entry_idx = index\n",
    "                                                    if entry_idx < tp_idx:\n",
    "                                                        entry_hit.append(entry_idx)\n",
    "                                                        break\n",
    "                                                        \n",
    "                                                elif min([tp_idx, sl_idx]) == sl_idx:\n",
    "                                                    entry_idx = index\n",
    "                                                    entry_idx = index\n",
    "                                                    if entry_idx < sl_idx:\n",
    "                                                        entry_hit.append(entry_idx)\n",
    "                                                        break                  \n",
    "                                                    \n",
    "                                ############## Metrics ###########\n",
    "                                \n",
    "                                m5_ema_difference = normalised_difference(data[\"trend\"].iloc[last_vector_peak],data[\"moving average\"].iloc[last_vector_peak])\n",
    "                                m5_peak_difference = normalised_difference(data[\"peak trend\"].iloc[last_vector_peak], data[\"close\"].iloc[last_vector_peak]) \n",
    "                                m5_trough_difference = normalised_difference(data[\"trough trend\"].iloc[last_vector_peak], data[\"close\"].iloc[last_vector_peak]) \n",
    "    \n",
    "                                m5_log_returns = compute_timeframe_returns(data[\"trend\"],0,1000)\n",
    "                                m5_peak_returns = compute_timeframe_returns(data[\"peak trend\"],0,1000)\n",
    "                                m5_trough_returns = compute_timeframe_returns(data[\"trough trend\"],0,1000) \n",
    "    \n",
    "                                trade_size = normalised_difference(tp,sl)\n",
    "                                \n",
    "                                log_trade(data)                                \n",
    "                            \n",
    "                                \n",
    "                                shorts.append(last_peak_idx_m5)\n",
    "                                signal_delay.append(len(data) - last_vector_peak)\n",
    "                                \n",
    "                                close_shorts.append(data[\"close\"].iloc[last_peak_idx_m5])\n",
    "                                \n",
    "                                print(f\"Short at idx {df_idx}\")\n",
    "                                plt.figure(figsize = (12,6))\n",
    "                                plt.plot(numbers, data[\"close\"], color = \"green\", alpha = 0.8)\n",
    "                                plt.plot(numbers, trend, color = \"blue\", linestyle = \"-\")\n",
    "                                plt.plot(numbers, upper_band, color = \"blue\", linestyle = \"--\")\n",
    "                                plt.plot(numbers, lower_band, color = \"blue\", linestyle = \"--\")\n",
    "                                plt.scatter(numbers[valid_peaks_m5], data[\"close\"].iloc[valid_peaks_m5], marker = \"v\", color = \"red\")\n",
    "                                plt.scatter(numbers[valid_troughs_m5], data[\"close\"].iloc[valid_troughs_m5], marker = \"^\", color = \"purple\")\n",
    "                                plt.scatter(numbers[last_vector_peak], data[\"close\"].iloc[last_vector_peak], marker = \"v\", color = \"purple\")\n",
    "                                plt.fill_between(x = numbers, y1 = overbought, y2 = upper_band, color = \"red\", alpha = 0.3)\n",
    "                                plt.fill_between(x = numbers, y1 = oversold, y2 = lower_band, color = \"green\", alpha = 0.3)\n",
    "                                plt.hlines(y = sl ,xmin = last_vector_peak, xmax = 2200, color =\"red\", alpha = 0.8)\n",
    "                                plt.hlines(y = tp ,xmin = last_vector_peak, xmax = 2200, color =\"green\", alpha = 0.8)\n",
    "                                plt.hlines(y = entry_lvl, xmin = last_vector_peak, xmax = 2200, color =\"blue\", alpha = 0.8)\n",
    "    \n",
    "                                plt.plot(numbers, peak_trend, alpha = 0.5, color = \"red\", linestyle = \"--\")\n",
    "                                plt.plot(numbers, trough_trend, alpha = 0.5, color = \"green\", linestyle = \"--\")\n",
    "                                \n",
    "                                plt.grid()\n",
    "                                plt.show()\n",
    "                \n",
    "            if len(shorts) > 0:\n",
    "                latest_short_idx = shorts[-1]\n",
    "                \n",
    "                if data[\"close\"].iloc[last_peak_idx_m5] != close_shorts[-1]: #data[\"close\"].iloc[close_shorts[-1]]:\n",
    "\n",
    "                    compute_fib(data)\n",
    "                    print(f\"Entry lvl is {entry_lvl}\")\n",
    "                    compute_sl(data)\n",
    "                    compute_tp(data)    \n",
    "                    tp = conservative_tp()\n",
    "                    \n",
    "                    ### Establish risk reward, regardless of hit entry or not, assume market order\n",
    "\n",
    "                    rr = risk_reward(sl, data[\"close\"].iloc[-1],tp)\n",
    "\n",
    "                    if rr > 0.8:\n",
    "\n",
    "                        if rr < 1:\n",
    "                            loss_rr = 2-rr\n",
    "                        else:\n",
    "                            loss_rr = 1\n",
    "                        \n",
    "                        if data[\"close\"].iloc[-1] < sl:\n",
    "                            \n",
    "                    \n",
    "                            df_idx = idx + last_vector_peak - 2000\n",
    "        \n",
    "                            if df_idx < bars - 2000:\n",
    "    \n",
    "                                print(f\"RR = {rr}\") if rr is not None else print(\"RR failed to be computed\")\n",
    "                                print(f\"Loss RR = {-loss_rr}\") if loss_rr is not None else print(\"Loss RR failed to be computed\")\n",
    "    \n",
    "                                print(f\"sl == {sl}\") if entry_lvl != None else print(\"None\")\n",
    "                                print(f\"entry = {entry_lvl}\") if entry_lvl != None else print(\"None\")\n",
    "                                print(f\"tp == {tp}\") if tp != None else print(\"None\")                          \n",
    "                                \n",
    "                            \n",
    "                                for index, val in enumerate(df[\"close\"].iloc[df_idx:] < tp):\n",
    "                                    if index < 2000:\n",
    "                                        \n",
    "                                    \n",
    "                                        if val == True:\n",
    "                                            tp_idx = index\n",
    "                                            break\n",
    "\n",
    "                                    else:\n",
    "                                        tp_idx = 9999\n",
    "                                        \n",
    "                                for index, val in enumerate(df[\"close\"].iloc[df_idx:] > sl):\n",
    "                                    if index < 2000:\n",
    "                                        \n",
    "                                        if val == True:\n",
    "                                            \n",
    "                                            sl_idx = index\n",
    "                                            break\n",
    "\n",
    "                                    else:\n",
    "                                        sl_idx = 9999\n",
    "\n",
    "                                if tp_idx != sl_idx:\n",
    "                                    \n",
    "                                            \n",
    "                                    if sl_idx  != None and tp_idx != None:\n",
    "                                        print(f\"sl_idx = {sl_idx}, tp_idx = {tp_idx}\")\n",
    "                                        if min([tp_idx, sl_idx]) == sl_idx:\n",
    "                                            short_sl_hit.append(sl_idx)\n",
    "                                            total_short_sl.append(sl_idx)\n",
    "                                            cum.append(loss_rr*-1)\n",
    "                                            total_cum.append(loss_rr*-1)\n",
    "                                            \n",
    "                                            print(\"SL Hit!\")\n",
    "                                        elif min([tp_idx, sl_idx]) == tp_idx:\n",
    "                                            short_tp_hit.append(tp_idx)\n",
    "                                            total_short_tp.append(tp_idx)\n",
    "                                            total_cum.append(rr*1)\n",
    "                                            cum.append(rr*1)\n",
    "                                            print(\"TP Hit!\")\n",
    "                                            \n",
    "                                    if data[\"close\"].iloc[-1] == entry_lvl:\n",
    "                                        entry_hit.append(1)\n",
    "                                        \n",
    "                                    if data[\"close\"].iloc[-1] < entry_lvl:\n",
    "                                        for index, boolean in data[\"close\"].iloc[df_idx:] > entry_lvl:\n",
    "                                            if index < 2000:\n",
    "                                                \n",
    "                                                if boolean == True:\n",
    "                                                    if min([tp_idx, sl_idx]) == tp_idx:\n",
    "                                                        entry_idx = index\n",
    "                                                        if entry_idx < tp_idx:\n",
    "                                                            entry_hit.append(entry_idx)\n",
    "                                                            break\n",
    "                                                            \n",
    "                                                    elif min([tp_idx, sl_idx]) == sl_idx:\n",
    "                                                        entry_idx = index\n",
    "                                                        entry_idx = index\n",
    "                                                        if entry_idx < sl_idx:\n",
    "                                                            entry_hit.append(entry_idx)\n",
    "                                                            break    \n",
    "    \n",
    "                                    ############## Metrics ###########\n",
    "                                        \n",
    "                                    m5_ema_difference = normalised_difference(data[\"trend\"].iloc[last_vector_peak],data[\"moving average\"].iloc[last_vector_peak])\n",
    "                                    m5_peak_difference = normalised_difference(data[\"peak trend\"].iloc[last_vector_peak], data[\"close\"].iloc[last_vector_peak]) \n",
    "                                    m5_trough_difference = normalised_difference(data[\"trough trend\"].iloc[last_vector_peak], data[\"close\"].iloc[last_vector_peak]) \n",
    "    \n",
    "                                    m5_log_returns = compute_timeframe_returns(data[\"trend\"],0,1000)\n",
    "                                    m5_peak_returns = compute_timeframe_returns(data[\"peak trend\"],0,1000)\n",
    "                                    m5_trough_returns = compute_timeframe_returns(data[\"trough trend\"],0,1000)  \n",
    "    \n",
    "                                    trade_size = normalised_difference(tp,sl)\n",
    "                                    \n",
    "                                    log_trade(data)\n",
    "                                                        \n",
    "                \n",
    "                                    signal_delay.append(len(data) - last_vector_peak)\n",
    "                                    shorts.append(last_peak_idx_m5)\n",
    "                                    \n",
    "                                    close_shorts.append(data[\"close\"].iloc[last_peak_idx_m5])\n",
    "                                    \n",
    "                                    print(f\"Short at idx {df_idx}\")\n",
    "                                    plt.figure(figsize = (12,6))\n",
    "                                    plt.plot(numbers, data[\"close\"], color = \"green\", alpha = 0.8)\n",
    "                                    plt.plot(numbers, trend, color = \"blue\", linestyle = \"-\")\n",
    "                                    plt.plot(numbers, upper_band, color = \"blue\", linestyle = \"--\")\n",
    "                                    plt.plot(numbers, lower_band, color = \"blue\", linestyle = \"--\")\n",
    "                                    plt.scatter(numbers[valid_peaks_m5], data[\"close\"].iloc[valid_peaks_m5], marker = \"v\", color = \"red\")\n",
    "                                    plt.scatter(numbers[valid_troughs_m5], data[\"close\"].iloc[valid_troughs_m5], marker = \"^\", color = \"purple\")\n",
    "                                    plt.scatter(numbers[last_vector_peak], data[\"close\"].iloc[last_vector_peak], marker = \"v\", color = \"purple\")\n",
    "                                    plt.fill_between(x = numbers, y1 = overbought, y2 = upper_band, color = \"red\", alpha = 0.3)\n",
    "                                    plt.fill_between(x = numbers, y1 = oversold, y2 = lower_band, color = \"green\", alpha = 0.3)\n",
    "                                    plt.hlines(y = sl ,xmin = last_vector_peak, xmax = 2200, color =\"red\", alpha = 0.8)\n",
    "                                    plt.hlines(y = tp ,xmin = last_vector_peak, xmax = 2200, color =\"green\", alpha = 0.8)\n",
    "                                    plt.hlines(y = entry_lvl, xmin = last_vector_peak, xmax = 2200, color =\"blue\", alpha = 0.8)\n",
    "    \n",
    "                                    plt.plot(numbers, peak_trend, alpha = 0.5, color = \"red\", linestyle = \"--\")\n",
    "                                    plt.plot(numbers, trough_trend, alpha = 0.5, color = \"green\", linestyle = \"--\")                                    \n",
    "                                    \n",
    "                                    plt.grid()\n",
    "                                    plt.show()\n",
    "                        \n",
    "                    \n",
    "            \n",
    "    if macro_slope_m5 > 0:\n",
    "        \n",
    "        if  lower_band[last_vector_trough] <= data[\"low\"].iloc[last_vector_trough] <= oversold[last_vector_trough]:\n",
    "\n",
    "            if longs == []:\n",
    "\n",
    "                compute_fib(data)\n",
    "                print(f\"Entry lvl is {entry_lvl}\")\n",
    "                compute_sl(data)\n",
    "                compute_tp(data)\n",
    "                tp = conservative_tp()\n",
    "\n",
    "                ### Establish risk reward, regardless of hit entry or not, assume market order\n",
    "\n",
    "                rr = risk_reward(sl, data[\"close\"].iloc[-1],tp)\n",
    "                if rr > 0.8:\n",
    "                    \n",
    "                    if rr < 1:\n",
    "                        loss_rr = 2-rr\n",
    "                    else:\n",
    "                        loss_rr = 1\n",
    "                     \n",
    "                    df_idx = idx + last_vector_trough - 2000\n",
    "    \n",
    "                    if data[\"close\"].iloc[-1] > sl:\n",
    "                        \n",
    "    \n",
    "                        if df_idx < bars - 2000:\n",
    "                            \n",
    "                            \n",
    "                            print(f\"RR = {rr}\") if rr is not None else print(\"RR failed to be computed\")\n",
    "                            print(f\"Loss RR = {-loss_rr}\") if loss_rr is not None else print(\"Loss RR failed to be computed\")\n",
    "\n",
    "                            print(f\"sl == {sl}\") if entry_lvl != None else print(\"None\")\n",
    "                            print(f\"entry = {entry_lvl}\") if entry_lvl != None else print(\"None\")\n",
    "                            print(f\"tp == {tp}\") if tp != None else print(\"None\")                     \n",
    "                            \n",
    "                        \n",
    "                            for index, val in enumerate(df[\"close\"].iloc[df_idx:] > tp):\n",
    "                                if index < 2000:\n",
    "                                    \n",
    "                                    if val == True:\n",
    "                                        tp_idx = index\n",
    "                                        break\n",
    "\n",
    "                                else:\n",
    "                                    tp_idx = 9999\n",
    "                            for index, val in enumerate(df[\"close\"].iloc[df_idx:] < sl):\n",
    "                                if index < 2000:\n",
    "                                    \n",
    "                                    if val == True:\n",
    "                                        sl_idx = index\n",
    "                                        break\n",
    "                                else:\n",
    "                                    sl_idx = 9999\n",
    "\n",
    "                            if sl_idx != tp_idx:\n",
    "                                \n",
    "                                    \n",
    "                                if sl_idx  != None and tp_idx != None:\n",
    "                                    print(f\"sl_idx = {sl_idx}, tp_idx = {tp_idx}\")\n",
    "                                    \n",
    "                                    if min([tp_idx, sl_idx]) == sl_idx:\n",
    "                                        long_sl_hit.append(sl_idx)\n",
    "                                        total_long_sl.append(sl_idx)\n",
    "                                        cum.append(loss_rr*-1)\n",
    "                                        total_cum.append(loss_rr*-1)\n",
    "                                        \n",
    "                                        print(\"SL Hit!\")\n",
    "                                    elif min([tp_idx, sl_idx]) == tp_idx:\n",
    "                                        long_tp_hit.append(tp_idx)\n",
    "                                        total_long_tp.append(tp_idx)\n",
    "                                        total_cum.append(rr*1)\n",
    "                                        cum.append(rr*1)\n",
    "                                        print(\"TP Hit!\")\n",
    "                                    \n",
    "                                if data[\"close\"].iloc[-1] == entry_lvl:\n",
    "                                    entry_hit.append(1)\n",
    "                                if data[\"close\"].iloc[-1] < entry_lvl:\n",
    "                                    for index, boolean in data[\"close\"].iloc[df_idx:] > entry_lvl:\n",
    "                                        if boolean == True:\n",
    "                                            if index < 2000:\n",
    "                                                \n",
    "                                                if min([tp_idx, sl_idx]) == tp_idx:\n",
    "                                                    entry_idx = index\n",
    "                                                    if entry_idx < tp_idx:\n",
    "                                                        entry_hit.append(entry_idx)\n",
    "                                                        break\n",
    "                                                        \n",
    "                                                elif min([tp_idx, sl_idx]) == sl_idx:\n",
    "                                                    entry_idx = index\n",
    "                                                    entry_idx = index\n",
    "                                                    if entry_idx < sl_idx:\n",
    "                                                        entry_hit.append(entry_idx)\n",
    "                                                        break                                 \n",
    "    \n",
    "                                ############## Metrics ###########\n",
    "                                \n",
    "                                m5_ema_difference = normalised_difference(data[\"trend\"].iloc[last_vector_trough],data[\"moving average\"].iloc[last_vector_trough])\n",
    "                                m5_peak_difference = normalised_difference(data[\"peak trend\"].iloc[last_vector_trough], data[\"close\"].iloc[last_vector_trough]) \n",
    "                                m5_trough_difference = normalised_difference(data[\"trough trend\"].iloc[last_vector_trough], data[\"close\"].iloc[last_vector_trough]) \n",
    "    \n",
    "                                m5_log_returns = compute_timeframe_returns(data[\"trend\"],0,1000)\n",
    "                                m5_peak_returns = compute_timeframe_returns(data[\"peak trend\"],0,1000)\n",
    "                                m5_trough_returns = compute_timeframe_returns(data[\"trough trend\"],0,1000)    \n",
    "    \n",
    "                                trade_size = normalised_difference(tp,sl)\n",
    "                                \n",
    "                                log_trade(data)\n",
    "                                \n",
    "                                signal_delay.append(len(data) - last_vector_trough)\n",
    "                                longs.append(last_vector_trough)\n",
    "                                close_longs.append(data[\"close\"].iloc[last_trough_idx_m5])\n",
    "                                print(f\"Long at idx {df_idx}\")\n",
    "                                plt.figure(figsize = (12,6))\n",
    "                                plt.plot(numbers, data[\"close\"], color = \"green\", alpha = 0.8)\n",
    "                                plt.plot(numbers, trend, color = \"blue\", linestyle = \"-\")\n",
    "                                plt.plot(numbers, upper_band, color = \"blue\", linestyle = \"--\")\n",
    "                                plt.plot(numbers, lower_band, color = \"blue\", linestyle = \"--\")\n",
    "                                plt.scatter(numbers[valid_peaks_m5], data[\"close\"].iloc[valid_peaks_m5], marker = \"v\", color = \"red\")\n",
    "                                plt.scatter(numbers[valid_troughs_m5], data[\"close\"].iloc[valid_troughs_m5], marker = \"^\", color = \"purple\")\n",
    "                                plt.scatter(numbers[last_vector_trough], data[\"close\"].iloc[last_vector_trough], marker = \"^\", color = \"purple\")\n",
    "                                plt.fill_between(x = numbers, y1 = overbought, y2 = upper_band, color = \"red\", alpha = 0.3)\n",
    "                                plt.fill_between(x = numbers, y1 = oversold, y2 = lower_band, color = \"green\", alpha = 0.3)\n",
    "                                plt.hlines(y = sl ,xmin = last_vector_trough, xmax = 2200, color =\"red\", alpha = 0.8)\n",
    "                                plt.hlines(y = tp ,xmin = last_vector_trough, xmax = 2200, color =\"green\", alpha = 0.8)\n",
    "                                plt.hlines(y = entry_lvl, xmin = last_vector_trough, xmax = 2200, color =\"blue\", alpha = 0.8)  \n",
    "    \n",
    "                                plt.plot(numbers, peak_trend, alpha = 0.5, color = \"red\", linestyle = \"--\")\n",
    "                                plt.plot(numbers, trough_trend, alpha = 0.5, color = \"green\", linestyle = \"--\")\n",
    "                                \n",
    "                                plt.grid()\n",
    "                                plt.show()\n",
    "                \n",
    "            if len(longs) > 0:\n",
    "                latest_long_idx = longs[-1]\n",
    "                \n",
    "                if data[\"close\"].iloc[last_trough_idx_m5] != close_longs[-1]: #data[\"close\"].iloc[close_longs[-1]]:\n",
    "\n",
    "                    compute_fib(data)\n",
    "                    print(f\"Entry lvl is {entry_lvl}\")\n",
    "                    compute_sl(data)\n",
    "                    compute_tp(data) \n",
    "                    tp = conservative_tp()\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "                    ### Establish risk reward, regardless of hit entry or not, assume market order\n",
    "\n",
    "                    rr = risk_reward(sl, data[\"close\"].iloc[-1],tp)\n",
    "\n",
    "                    if rr > 0.8:\n",
    "                        \n",
    "\n",
    "                        if rr < 1:\n",
    "                            loss_rr = 2-rr\n",
    "                        else:\n",
    "                            loss_rr = 1\n",
    "                        \n",
    "                        if data[\"close\"].iloc[-1] > sl:\n",
    "    \n",
    "                            \n",
    "                        \n",
    "                            df_idx = idx + last_vector_trough - 2000\n",
    "                            \n",
    "                            if df_idx < bars - 2000:\n",
    "\n",
    "                                print(f\"RR = {rr}\") if rr is not None else print(\"RR failed to be computed\")\n",
    "                                print(f\"Loss RR = {-loss_rr}\") if loss_rr is not None else print(\"Loss RR failed to be computed\")\n",
    "    \n",
    "                                print(f\"sl == {sl}\") if entry_lvl != None else print(\"None\")\n",
    "                                print(f\"entry = {entry_lvl}\") if entry_lvl != None else print(\"None\")\n",
    "                                print(f\"tp == {tp}\") if tp != None else print(\"None\")\n",
    "                                \n",
    "                            \n",
    "                                for index, val in enumerate(df[\"close\"].iloc[df_idx:] > tp):\n",
    "                                    if index < 2000:\n",
    "                                        \n",
    "                                        if val == True:\n",
    "                                            tp_idx = index\n",
    "                                            break\n",
    "\n",
    "                                    else:\n",
    "                                        tp_idx = 9999\n",
    "                                for index, val in enumerate(df[\"close\"].iloc[df_idx:] < sl):\n",
    "                                    if index < 2000:\n",
    "                                        \n",
    "                                        if val == True:\n",
    "                                            sl_idx = index\n",
    "                                            break\n",
    "                                    else:\n",
    "                                        sl_idx = 9999\n",
    "\n",
    "                                if tp_idx != sl_idx:\n",
    "                                    \n",
    "                                        \n",
    "                                    if sl_idx  != None and tp_idx != None:\n",
    "                                        print(f\"sl_idx = {sl_idx}, tp_idx = {tp_idx}\")\n",
    "                                        \n",
    "                                        if min([tp_idx, sl_idx]) == sl_idx:\n",
    "                                            long_sl_hit.append(sl_idx)\n",
    "                                            total_long_sl.append(sl_idx)\n",
    "                                            cum.append(loss_rr*-1)\n",
    "                                            total_cum.append(loss_rr*-1)\n",
    "                                            \n",
    "                                            print(\"SL Hit!\")\n",
    "                                        elif min([tp_idx, sl_idx]) == tp_idx:\n",
    "                                            long_tp_hit.append(tp_idx)\n",
    "                                            total_long_tp.append(tp_idx)\n",
    "                                            total_cum.append(rr*1)\n",
    "                                            cum.append(rr*1)\n",
    "                                            print(\"TP Hit!\")\n",
    "                                        \n",
    "                                    if data[\"close\"].iloc[-1] == entry_lvl:\n",
    "                                        entry_hit.append(1)\n",
    "                                        \n",
    "                                    if data[\"close\"].iloc[-1] > entry_lvl:\n",
    "                                        for index, boolean in data[\"close\"].iloc[df_idx:] < entry_lvl:\n",
    "                                            if index < 2000:\n",
    "                                                \n",
    "                                                if boolean == True:\n",
    "                                                    if min([tp_idx, sl_idx]) == tp_idx:\n",
    "                                                        entry_idx = index\n",
    "                                                        if entry_idx < tp_idx:\n",
    "                                                            entry_hit.append(entry_idx)\n",
    "                                                            break\n",
    "                                                            \n",
    "                                                    elif min([tp_idx, sl_idx]) == sl_idx:\n",
    "                                                        entry_idx = index\n",
    "                                                        entry_idx = index\n",
    "                                                        if entry_idx < sl_idx:\n",
    "                                                            entry_hit.append(entry_idx)\n",
    "                                                            break    \n",
    "    \n",
    "                                    ############## Metrics ###########\n",
    "                                    \n",
    "                                    m5_ema_difference = normalised_difference(data[\"trend\"].iloc[last_vector_trough],data[\"moving average\"].iloc[last_vector_trough])\n",
    "                                    m5_peak_difference = normalised_difference(data[\"peak trend\"].iloc[last_vector_trough], data[\"close\"].iloc[last_vector_trough]) \n",
    "                                    m5_trough_difference = normalised_difference(data[\"trough trend\"].iloc[last_vector_trough], data[\"close\"].iloc[last_vector_trough]) \n",
    "    \n",
    "                                    m5_log_returns = compute_timeframe_returns(data[\"trend\"],0,1000)\n",
    "                                    m5_peak_returns = compute_timeframe_returns(data[\"peak trend\"],0,1000)\n",
    "                                    m5_trough_returns = compute_timeframe_returns(data[\"trough trend\"],0,1000)   \n",
    "    \n",
    "                                    trade_size = normalised_difference(tp,sl)\n",
    "                                    \n",
    "                                    log_trade(data)\n",
    "                                                    \n",
    "                                    signal_delay.append(len(data) - last_vector_trough)\n",
    "                                    longs.append(last_vector_trough)\n",
    "                                    close_longs.append(data[\"close\"].iloc[last_trough_idx_m5])\n",
    "                                    print(f\"Long at idx {df_idx}\")\n",
    "                                    plt.figure(figsize = (12,6))\n",
    "                                    plt.plot(numbers, data[\"close\"], color = \"green\", alpha = 0.8)\n",
    "                                    plt.plot(numbers, trend, color = \"blue\", linestyle = \"-\")\n",
    "                                    plt.plot(numbers, data[\"upper band\"], color = \"blue\", linestyle = \"--\")\n",
    "                                    plt.plot(numbers, data[\"lower band\"], color = \"blue\", linestyle = \"--\")\n",
    "                                    plt.scatter(numbers[valid_peaks_m5], data[\"close\"].iloc[valid_peaks_m5], marker = \"v\", color = \"red\")\n",
    "                                    plt.scatter(numbers[valid_troughs_m5], data[\"close\"].iloc[valid_troughs_m5], marker = \"^\", color = \"purple\")\n",
    "                                    plt.scatter(numbers[last_vector_trough], data[\"close\"].iloc[last_vector_trough], marker = \"v\", color = \"purple\")\n",
    "                                    plt.fill_between(x = numbers, y1 = overbought, y2 = upper_band, color = \"red\", alpha = 0.3)\n",
    "                                    plt.fill_between(x = numbers, y1 = oversold, y2 = lower_band, color = \"green\", alpha = 0.3) \n",
    "                                    plt.hlines(y = sl ,xmin = last_vector_trough, xmax = 2200, color =\"red\", alpha = 0.8)\n",
    "                                    plt.hlines(y = tp ,xmin = last_vector_trough, xmax = 2200, color =\"green\", alpha = 0.8)\n",
    "                                    plt.hlines(y = entry_lvl, xmin = last_vector_trough, xmax = 2200, color =\"blue\", alpha = 0.8)  \n",
    "    \n",
    "                                    plt.plot(numbers, peak_trend, alpha = 0.5, color = \"red\", linestyle = \"--\")\n",
    "                                    plt.plot(numbers, trough_trend, alpha = 0.5, color = \"green\", linestyle = \"--\")\n",
    "                                    \n",
    "                                    plt.grid()\n",
    "                                    plt.show()\n",
    "        \n",
    "    if idx in progress:\n",
    "        print(F\"###################### PROGRESS {100*idx/bars}% TO COMPLETION ######################\")\n",
    "    #all_slopes.append(macro_slope_m5)\n",
    "        #print(f\"Slope from {idx - 2000} to {idx} computed successfully\") if macro_slope_m5 != None else None\n",
    "    \n",
    "length = [len(short_tp_hit), len(short_sl_hit)]\n",
    "labels = [\"TP Hit\", \"SL Hit\"]\n",
    "\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "from matplotlib import gridspec\n",
    "gs = gridspec.GridSpec(2,2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "ax3 = fig.add_subplot(gs[1,0])\n",
    "ax4 = fig.add_subplot(gs[1,1])\n",
    "\n",
    "ax1.set_title(f\"Short Trade Summary for {symbol}\")\n",
    "\n",
    "length = [len(short_tp_hit), len(short_sl_hit)]\n",
    "labels = [\"TP Hit\", \"SL Hit\"]\n",
    "bars = ax1.bar(labels, length, color = [\"green\",\"red\"], alpha = 0.6)\n",
    "ax1.bar_label(bars, padding = 1)\n",
    "\n",
    "ax2.set_title(f\"Long Trade Summary for {symbol}\")\n",
    "length = [len(long_tp_hit), len(long_sl_hit)]\n",
    "labels = [\"TP Hit\", \"SL Hit\"]\n",
    "bars = ax2.bar(labels, length, color = [\"green\",\"red\"], alpha = 0.6)\n",
    "ax2.bar_label(bars, padding = 1)\n",
    "\n",
    "ax3.set_title(f\"Total Trade Summary for {symbol}\")\n",
    "total_trades = len(shorts) + len(longs)\n",
    "total_tp_hit = len(short_tp_hit) + len(long_tp_hit)\n",
    "total_sl_hit = len(short_sl_hit) + len(long_sl_hit)\n",
    "length = [round(100*total_tp_hit/total_trades,2), round(100*total_sl_hit/ total_trades,2)]\n",
    "labels = [\"TP Hit %\", \"SL Hit %\"]\n",
    "bars = ax3.bar(labels, length, color = [\"blue\",\"red\"], alpha = 0.6)\n",
    "ax3.bar_label(bars, padding = 1)\n",
    "\n",
    "profit = np.array(cum).reshape(-1,1)\n",
    "profit = profit * 500\n",
    "profit = profit.cumsum()\n",
    "starting_balance = 200000\n",
    "equity = starting_balance + profit\n",
    "numbers = np.arange(0, len(equity))\n",
    "ax4.set_title(f\"Running equity with start.equity of {starting_balance}\")\n",
    "ax4.plot(numbers, equity, color= \"red\", alpha = 0.8)\n",
    "#plt.text(f\"No. of trades taken = {len(shorts) + len(longs)}\")\n",
    "ax4.scatter(numbers[-1], equity[-1], color=\"black\", marker=\"*\", label = f\"Last equity value = {equity[-1]}\")\n",
    "ax4.grid()\n",
    "ax4.legend()\n",
    "\n",
    "plt.savefig(f\"MV Strategy Summary for {symbol}.png\", bbox_inches=\"tight\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14aae9e-6f73-43c8-bc56-1262e2503cd3",
   "metadata": {},
   "source": [
    "### Backtest Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67fd21-1618-4e87-8e8a-a6426b360a79",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f3688f3-77b7-446a-92a6-851646c27ad8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Long': {'long_sl_hit': [157,\n",
       "   70,\n",
       "   49,\n",
       "   82,\n",
       "   57,\n",
       "   49,\n",
       "   6,\n",
       "   80,\n",
       "   70,\n",
       "   55,\n",
       "   13,\n",
       "   8,\n",
       "   106,\n",
       "   40,\n",
       "   29,\n",
       "   13,\n",
       "   5,\n",
       "   17,\n",
       "   124,\n",
       "   52,\n",
       "   23,\n",
       "   26,\n",
       "   27,\n",
       "   10,\n",
       "   23,\n",
       "   34,\n",
       "   6,\n",
       "   28,\n",
       "   43,\n",
       "   54,\n",
       "   22,\n",
       "   16,\n",
       "   24,\n",
       "   29,\n",
       "   4,\n",
       "   11,\n",
       "   10,\n",
       "   215,\n",
       "   192,\n",
       "   17,\n",
       "   4,\n",
       "   15,\n",
       "   43,\n",
       "   63,\n",
       "   77,\n",
       "   58,\n",
       "   19,\n",
       "   21,\n",
       "   170,\n",
       "   217,\n",
       "   217,\n",
       "   39,\n",
       "   1004,\n",
       "   147,\n",
       "   147,\n",
       "   20,\n",
       "   12,\n",
       "   7,\n",
       "   17,\n",
       "   310,\n",
       "   14,\n",
       "   40,\n",
       "   28,\n",
       "   7,\n",
       "   36,\n",
       "   17,\n",
       "   17,\n",
       "   33,\n",
       "   49,\n",
       "   238,\n",
       "   19,\n",
       "   10,\n",
       "   53,\n",
       "   12,\n",
       "   119,\n",
       "   208,\n",
       "   208,\n",
       "   34,\n",
       "   22,\n",
       "   32,\n",
       "   89,\n",
       "   9,\n",
       "   600,\n",
       "   204,\n",
       "   100,\n",
       "   10,\n",
       "   34,\n",
       "   15,\n",
       "   160,\n",
       "   55,\n",
       "   31,\n",
       "   20,\n",
       "   31,\n",
       "   137,\n",
       "   3,\n",
       "   186,\n",
       "   290,\n",
       "   282,\n",
       "   11,\n",
       "   110,\n",
       "   365,\n",
       "   257,\n",
       "   195,\n",
       "   76,\n",
       "   120,\n",
       "   249,\n",
       "   12,\n",
       "   228,\n",
       "   203,\n",
       "   17,\n",
       "   37,\n",
       "   75,\n",
       "   5,\n",
       "   31,\n",
       "   98,\n",
       "   24,\n",
       "   23,\n",
       "   87,\n",
       "   38,\n",
       "   241,\n",
       "   45,\n",
       "   103,\n",
       "   12,\n",
       "   566,\n",
       "   373,\n",
       "   29,\n",
       "   35,\n",
       "   12,\n",
       "   6,\n",
       "   4,\n",
       "   41,\n",
       "   12,\n",
       "   116,\n",
       "   63,\n",
       "   3,\n",
       "   4,\n",
       "   26,\n",
       "   26,\n",
       "   8,\n",
       "   89,\n",
       "   12,\n",
       "   6,\n",
       "   77,\n",
       "   18,\n",
       "   202,\n",
       "   26,\n",
       "   526,\n",
       "   88,\n",
       "   12,\n",
       "   7,\n",
       "   7,\n",
       "   31,\n",
       "   5,\n",
       "   12,\n",
       "   16,\n",
       "   92,\n",
       "   40,\n",
       "   74,\n",
       "   620,\n",
       "   41,\n",
       "   26,\n",
       "   23,\n",
       "   167,\n",
       "   27,\n",
       "   210,\n",
       "   207,\n",
       "   175,\n",
       "   84,\n",
       "   80,\n",
       "   12,\n",
       "   13,\n",
       "   856,\n",
       "   204,\n",
       "   173,\n",
       "   2,\n",
       "   89,\n",
       "   151,\n",
       "   27,\n",
       "   6,\n",
       "   15,\n",
       "   23,\n",
       "   5,\n",
       "   213,\n",
       "   3,\n",
       "   497,\n",
       "   9,\n",
       "   388,\n",
       "   213,\n",
       "   103,\n",
       "   17,\n",
       "   58,\n",
       "   4,\n",
       "   537,\n",
       "   9,\n",
       "   64,\n",
       "   44,\n",
       "   161,\n",
       "   8,\n",
       "   39,\n",
       "   227,\n",
       "   259,\n",
       "   79,\n",
       "   721,\n",
       "   52,\n",
       "   146,\n",
       "   136,\n",
       "   84,\n",
       "   1214,\n",
       "   69,\n",
       "   14,\n",
       "   7,\n",
       "   19,\n",
       "   129,\n",
       "   83,\n",
       "   47,\n",
       "   12,\n",
       "   12,\n",
       "   291,\n",
       "   284,\n",
       "   8,\n",
       "   58,\n",
       "   58,\n",
       "   10,\n",
       "   223,\n",
       "   28,\n",
       "   62,\n",
       "   63,\n",
       "   10,\n",
       "   78,\n",
       "   81,\n",
       "   44,\n",
       "   21,\n",
       "   9,\n",
       "   368,\n",
       "   191,\n",
       "   107,\n",
       "   148,\n",
       "   228,\n",
       "   92,\n",
       "   8,\n",
       "   84,\n",
       "   13,\n",
       "   48,\n",
       "   66,\n",
       "   7,\n",
       "   428,\n",
       "   32,\n",
       "   11,\n",
       "   32,\n",
       "   562,\n",
       "   227,\n",
       "   32,\n",
       "   6,\n",
       "   89,\n",
       "   89,\n",
       "   14,\n",
       "   12,\n",
       "   11,\n",
       "   18,\n",
       "   76,\n",
       "   70,\n",
       "   20,\n",
       "   2,\n",
       "   3,\n",
       "   84,\n",
       "   19,\n",
       "   28,\n",
       "   26,\n",
       "   60,\n",
       "   106,\n",
       "   190,\n",
       "   2,\n",
       "   288,\n",
       "   216,\n",
       "   35,\n",
       "   17,\n",
       "   95,\n",
       "   14,\n",
       "   84,\n",
       "   83,\n",
       "   20,\n",
       "   79,\n",
       "   19,\n",
       "   62,\n",
       "   60,\n",
       "   17,\n",
       "   11,\n",
       "   2,\n",
       "   195,\n",
       "   39,\n",
       "   73,\n",
       "   191,\n",
       "   173,\n",
       "   35,\n",
       "   63,\n",
       "   146],\n",
       "  'long_tp_hit': [89,\n",
       "   86,\n",
       "   65,\n",
       "   65,\n",
       "   65,\n",
       "   140,\n",
       "   140,\n",
       "   33,\n",
       "   182,\n",
       "   525,\n",
       "   309,\n",
       "   33,\n",
       "   22,\n",
       "   22,\n",
       "   22,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   13,\n",
       "   64,\n",
       "   10,\n",
       "   13,\n",
       "   94,\n",
       "   94,\n",
       "   54,\n",
       "   35,\n",
       "   288,\n",
       "   174,\n",
       "   89,\n",
       "   89,\n",
       "   128,\n",
       "   22,\n",
       "   69,\n",
       "   24,\n",
       "   14,\n",
       "   168,\n",
       "   69,\n",
       "   13,\n",
       "   0,\n",
       "   1,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   25,\n",
       "   14,\n",
       "   218,\n",
       "   196,\n",
       "   34,\n",
       "   189,\n",
       "   79,\n",
       "   44,\n",
       "   86,\n",
       "   43,\n",
       "   30,\n",
       "   197,\n",
       "   47,\n",
       "   17,\n",
       "   17,\n",
       "   52,\n",
       "   50,\n",
       "   50,\n",
       "   11,\n",
       "   165,\n",
       "   2,\n",
       "   40,\n",
       "   40,\n",
       "   532,\n",
       "   128,\n",
       "   53,\n",
       "   26,\n",
       "   26,\n",
       "   163,\n",
       "   86,\n",
       "   201,\n",
       "   136,\n",
       "   136,\n",
       "   88,\n",
       "   30,\n",
       "   1737,\n",
       "   94,\n",
       "   283,\n",
       "   20,\n",
       "   7,\n",
       "   61,\n",
       "   52,\n",
       "   101,\n",
       "   84,\n",
       "   84,\n",
       "   214,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   188,\n",
       "   188,\n",
       "   10,\n",
       "   10,\n",
       "   28,\n",
       "   0,\n",
       "   80,\n",
       "   141,\n",
       "   35,\n",
       "   10,\n",
       "   213,\n",
       "   15,\n",
       "   215,\n",
       "   164,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   287,\n",
       "   0,\n",
       "   0,\n",
       "   257,\n",
       "   244,\n",
       "   129,\n",
       "   129,\n",
       "   193,\n",
       "   166,\n",
       "   43,\n",
       "   68,\n",
       "   12,\n",
       "   12,\n",
       "   20,\n",
       "   20,\n",
       "   232,\n",
       "   27,\n",
       "   10,\n",
       "   176,\n",
       "   138,\n",
       "   26,\n",
       "   13,\n",
       "   31,\n",
       "   282,\n",
       "   226,\n",
       "   84,\n",
       "   63,\n",
       "   40,\n",
       "   12,\n",
       "   0,\n",
       "   41,\n",
       "   35,\n",
       "   7,\n",
       "   252,\n",
       "   152,\n",
       "   718,\n",
       "   56,\n",
       "   89,\n",
       "   64,\n",
       "   64,\n",
       "   182,\n",
       "   115,\n",
       "   45,\n",
       "   40,\n",
       "   46,\n",
       "   170,\n",
       "   228,\n",
       "   31,\n",
       "   41,\n",
       "   46,\n",
       "   146,\n",
       "   318,\n",
       "   193,\n",
       "   1233,\n",
       "   74,\n",
       "   11,\n",
       "   290,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   33,\n",
       "   6,\n",
       "   27,\n",
       "   27,\n",
       "   203,\n",
       "   128,\n",
       "   620,\n",
       "   26,\n",
       "   70,\n",
       "   32,\n",
       "   44,\n",
       "   79,\n",
       "   221,\n",
       "   177,\n",
       "   202,\n",
       "   152,\n",
       "   21,\n",
       "   11,\n",
       "   15,\n",
       "   4,\n",
       "   3,\n",
       "   230,\n",
       "   159,\n",
       "   144,\n",
       "   147,\n",
       "   53,\n",
       "   53,\n",
       "   53,\n",
       "   2,\n",
       "   47,\n",
       "   47,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   186,\n",
       "   53,\n",
       "   12,\n",
       "   236,\n",
       "   400,\n",
       "   26,\n",
       "   114,\n",
       "   215,\n",
       "   8,\n",
       "   25,\n",
       "   17,\n",
       "   39,\n",
       "   41,\n",
       "   139,\n",
       "   100,\n",
       "   100,\n",
       "   100,\n",
       "   179,\n",
       "   173,\n",
       "   542,\n",
       "   19,\n",
       "   1,\n",
       "   15,\n",
       "   15,\n",
       "   479,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   27,\n",
       "   4,\n",
       "   308,\n",
       "   41,\n",
       "   242,\n",
       "   23,\n",
       "   23,\n",
       "   23,\n",
       "   23,\n",
       "   61,\n",
       "   300,\n",
       "   45,\n",
       "   45,\n",
       "   45,\n",
       "   45,\n",
       "   43,\n",
       "   171,\n",
       "   5,\n",
       "   50,\n",
       "   218,\n",
       "   10,\n",
       "   47,\n",
       "   18,\n",
       "   255,\n",
       "   129,\n",
       "   129,\n",
       "   238,\n",
       "   46,\n",
       "   316,\n",
       "   37,\n",
       "   17,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   111,\n",
       "   105,\n",
       "   86,\n",
       "   36,\n",
       "   33,\n",
       "   19,\n",
       "   1241,\n",
       "   29,\n",
       "   167,\n",
       "   134,\n",
       "   26,\n",
       "   21,\n",
       "   187,\n",
       "   17,\n",
       "   57,\n",
       "   13,\n",
       "   140,\n",
       "   649,\n",
       "   281,\n",
       "   156,\n",
       "   125,\n",
       "   28,\n",
       "   212,\n",
       "   169,\n",
       "   0,\n",
       "   3,\n",
       "   73,\n",
       "   73,\n",
       "   43,\n",
       "   65,\n",
       "   51,\n",
       "   53,\n",
       "   175,\n",
       "   143,\n",
       "   31,\n",
       "   1,\n",
       "   9,\n",
       "   13,\n",
       "   12,\n",
       "   12,\n",
       "   267,\n",
       "   227,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   93,\n",
       "   93,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   0,\n",
       "   189,\n",
       "   63,\n",
       "   850,\n",
       "   763,\n",
       "   769,\n",
       "   56,\n",
       "   30,\n",
       "   84,\n",
       "   34,\n",
       "   0,\n",
       "   4,\n",
       "   45,\n",
       "   16,\n",
       "   16,\n",
       "   3,\n",
       "   223,\n",
       "   214,\n",
       "   113,\n",
       "   2,\n",
       "   515,\n",
       "   2,\n",
       "   5,\n",
       "   47,\n",
       "   345,\n",
       "   57,\n",
       "   29,\n",
       "   4,\n",
       "   248,\n",
       "   62,\n",
       "   13,\n",
       "   15,\n",
       "   81,\n",
       "   587,\n",
       "   1,\n",
       "   161,\n",
       "   136,\n",
       "   48,\n",
       "   45,\n",
       "   45,\n",
       "   0,\n",
       "   125,\n",
       "   1,\n",
       "   0,\n",
       "   53,\n",
       "   159,\n",
       "   25,\n",
       "   5,\n",
       "   122,\n",
       "   126,\n",
       "   76,\n",
       "   76,\n",
       "   76,\n",
       "   41,\n",
       "   41,\n",
       "   31,\n",
       "   12,\n",
       "   197,\n",
       "   111,\n",
       "   146,\n",
       "   24,\n",
       "   4,\n",
       "   1228,\n",
       "   80,\n",
       "   548,\n",
       "   65,\n",
       "   166,\n",
       "   147,\n",
       "   147,\n",
       "   147,\n",
       "   7,\n",
       "   32,\n",
       "   1118,\n",
       "   86,\n",
       "   286,\n",
       "   212,\n",
       "   208,\n",
       "   4,\n",
       "   33,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   6,\n",
       "   134,\n",
       "   67,\n",
       "   118,\n",
       "   45,\n",
       "   22,\n",
       "   81,\n",
       "   142,\n",
       "   162,\n",
       "   399,\n",
       "   399,\n",
       "   69,\n",
       "   194,\n",
       "   41,\n",
       "   101,\n",
       "   72,\n",
       "   110,\n",
       "   110,\n",
       "   35,\n",
       "   41,\n",
       "   12,\n",
       "   232,\n",
       "   37,\n",
       "   112,\n",
       "   160,\n",
       "   31,\n",
       "   31,\n",
       "   31,\n",
       "   31,\n",
       "   66,\n",
       "   66,\n",
       "   190,\n",
       "   47,\n",
       "   103,\n",
       "   76,\n",
       "   31,\n",
       "   13,\n",
       "   65,\n",
       "   65,\n",
       "   75,\n",
       "   24,\n",
       "   212,\n",
       "   184,\n",
       "   11,\n",
       "   38,\n",
       "   76,\n",
       "   1135,\n",
       "   0,\n",
       "   0,\n",
       "   99,\n",
       "   89,\n",
       "   89,\n",
       "   93,\n",
       "   29,\n",
       "   31,\n",
       "   30,\n",
       "   116,\n",
       "   48,\n",
       "   221,\n",
       "   33]},\n",
       " 'Short': {'short_sl_hit': [347,\n",
       "   21,\n",
       "   61,\n",
       "   243,\n",
       "   165,\n",
       "   0,\n",
       "   8,\n",
       "   11,\n",
       "   34,\n",
       "   178,\n",
       "   68,\n",
       "   171,\n",
       "   5,\n",
       "   10,\n",
       "   46,\n",
       "   21,\n",
       "   205,\n",
       "   179,\n",
       "   148,\n",
       "   280,\n",
       "   48,\n",
       "   38,\n",
       "   143,\n",
       "   55,\n",
       "   45,\n",
       "   272,\n",
       "   225,\n",
       "   294,\n",
       "   181,\n",
       "   63,\n",
       "   47,\n",
       "   103,\n",
       "   25,\n",
       "   170,\n",
       "   103,\n",
       "   19,\n",
       "   105,\n",
       "   99,\n",
       "   104,\n",
       "   6,\n",
       "   8,\n",
       "   34,\n",
       "   5,\n",
       "   87,\n",
       "   20,\n",
       "   27,\n",
       "   1,\n",
       "   37,\n",
       "   60,\n",
       "   34,\n",
       "   172,\n",
       "   72,\n",
       "   439,\n",
       "   27,\n",
       "   47,\n",
       "   204,\n",
       "   204,\n",
       "   56,\n",
       "   20,\n",
       "   19,\n",
       "   0,\n",
       "   263,\n",
       "   240,\n",
       "   124,\n",
       "   28,\n",
       "   125,\n",
       "   118,\n",
       "   8,\n",
       "   14,\n",
       "   30,\n",
       "   15,\n",
       "   56,\n",
       "   18,\n",
       "   16,\n",
       "   128,\n",
       "   7,\n",
       "   20,\n",
       "   6,\n",
       "   3,\n",
       "   62,\n",
       "   38,\n",
       "   0,\n",
       "   39,\n",
       "   254,\n",
       "   194,\n",
       "   194,\n",
       "   192,\n",
       "   12,\n",
       "   4,\n",
       "   221,\n",
       "   18,\n",
       "   97,\n",
       "   169,\n",
       "   25,\n",
       "   339,\n",
       "   4,\n",
       "   40,\n",
       "   21,\n",
       "   0,\n",
       "   17,\n",
       "   377,\n",
       "   12,\n",
       "   9,\n",
       "   63,\n",
       "   202,\n",
       "   250,\n",
       "   41,\n",
       "   208,\n",
       "   283,\n",
       "   215,\n",
       "   18,\n",
       "   199,\n",
       "   166,\n",
       "   152,\n",
       "   59,\n",
       "   59,\n",
       "   54,\n",
       "   51,\n",
       "   60,\n",
       "   60,\n",
       "   183,\n",
       "   20,\n",
       "   19,\n",
       "   5,\n",
       "   76,\n",
       "   59,\n",
       "   78,\n",
       "   52,\n",
       "   15,\n",
       "   30,\n",
       "   32,\n",
       "   84,\n",
       "   7,\n",
       "   103,\n",
       "   17,\n",
       "   13,\n",
       "   33,\n",
       "   10,\n",
       "   33,\n",
       "   96,\n",
       "   71,\n",
       "   97,\n",
       "   70,\n",
       "   0,\n",
       "   59,\n",
       "   52,\n",
       "   54,\n",
       "   5,\n",
       "   10,\n",
       "   16,\n",
       "   238,\n",
       "   125,\n",
       "   69,\n",
       "   53,\n",
       "   29,\n",
       "   48,\n",
       "   52,\n",
       "   11,\n",
       "   189,\n",
       "   31,\n",
       "   16,\n",
       "   16,\n",
       "   17,\n",
       "   179,\n",
       "   158,\n",
       "   21,\n",
       "   258,\n",
       "   31,\n",
       "   23,\n",
       "   47,\n",
       "   23,\n",
       "   67,\n",
       "   197,\n",
       "   155,\n",
       "   2,\n",
       "   204,\n",
       "   75,\n",
       "   69,\n",
       "   19,\n",
       "   9,\n",
       "   29,\n",
       "   88,\n",
       "   16,\n",
       "   12,\n",
       "   73,\n",
       "   51,\n",
       "   11,\n",
       "   198,\n",
       "   20,\n",
       "   32,\n",
       "   130,\n",
       "   88,\n",
       "   0,\n",
       "   471,\n",
       "   470,\n",
       "   475,\n",
       "   107,\n",
       "   18,\n",
       "   22,\n",
       "   20,\n",
       "   11,\n",
       "   102,\n",
       "   299,\n",
       "   29,\n",
       "   183,\n",
       "   209,\n",
       "   205,\n",
       "   77,\n",
       "   30,\n",
       "   169,\n",
       "   113,\n",
       "   3,\n",
       "   35,\n",
       "   1,\n",
       "   67,\n",
       "   11,\n",
       "   14,\n",
       "   138,\n",
       "   268,\n",
       "   156,\n",
       "   3,\n",
       "   80,\n",
       "   478,\n",
       "   17,\n",
       "   24,\n",
       "   48,\n",
       "   21,\n",
       "   109,\n",
       "   3,\n",
       "   37,\n",
       "   0,\n",
       "   9,\n",
       "   19,\n",
       "   70,\n",
       "   179,\n",
       "   119,\n",
       "   50,\n",
       "   50,\n",
       "   10,\n",
       "   183,\n",
       "   107,\n",
       "   42,\n",
       "   16,\n",
       "   131,\n",
       "   41,\n",
       "   68,\n",
       "   200,\n",
       "   199,\n",
       "   144,\n",
       "   9,\n",
       "   4,\n",
       "   2,\n",
       "   20,\n",
       "   11,\n",
       "   24,\n",
       "   185,\n",
       "   248,\n",
       "   70,\n",
       "   113,\n",
       "   47,\n",
       "   42,\n",
       "   35,\n",
       "   42,\n",
       "   3,\n",
       "   195,\n",
       "   10,\n",
       "   46,\n",
       "   97,\n",
       "   22,\n",
       "   58,\n",
       "   13,\n",
       "   164,\n",
       "   5,\n",
       "   14,\n",
       "   283,\n",
       "   138,\n",
       "   84,\n",
       "   29,\n",
       "   10,\n",
       "   46,\n",
       "   11,\n",
       "   104,\n",
       "   32,\n",
       "   2,\n",
       "   0,\n",
       "   83,\n",
       "   75,\n",
       "   13,\n",
       "   25,\n",
       "   79,\n",
       "   136,\n",
       "   180,\n",
       "   63,\n",
       "   118,\n",
       "   39],\n",
       "  'short_tp_hit': [12,\n",
       "   65,\n",
       "   457,\n",
       "   166,\n",
       "   138,\n",
       "   81,\n",
       "   43,\n",
       "   43,\n",
       "   202,\n",
       "   202,\n",
       "   259,\n",
       "   36,\n",
       "   45,\n",
       "   2,\n",
       "   13,\n",
       "   13,\n",
       "   14,\n",
       "   56,\n",
       "   227,\n",
       "   143,\n",
       "   72,\n",
       "   24,\n",
       "   28,\n",
       "   28,\n",
       "   146,\n",
       "   272,\n",
       "   253,\n",
       "   64,\n",
       "   64,\n",
       "   28,\n",
       "   18,\n",
       "   20,\n",
       "   621,\n",
       "   294,\n",
       "   178,\n",
       "   69,\n",
       "   14,\n",
       "   14,\n",
       "   14,\n",
       "   14,\n",
       "   95,\n",
       "   63,\n",
       "   17,\n",
       "   19,\n",
       "   13,\n",
       "   173,\n",
       "   237,\n",
       "   186,\n",
       "   117,\n",
       "   32,\n",
       "   11,\n",
       "   157,\n",
       "   13,\n",
       "   17,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   8,\n",
       "   0,\n",
       "   226,\n",
       "   176,\n",
       "   50,\n",
       "   280,\n",
       "   902,\n",
       "   13,\n",
       "   13,\n",
       "   9,\n",
       "   162,\n",
       "   5,\n",
       "   73,\n",
       "   73,\n",
       "   73,\n",
       "   67,\n",
       "   103,\n",
       "   33,\n",
       "   25,\n",
       "   20,\n",
       "   20,\n",
       "   239,\n",
       "   55,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   70,\n",
       "   46,\n",
       "   112,\n",
       "   9,\n",
       "   11,\n",
       "   275,\n",
       "   212,\n",
       "   216,\n",
       "   811,\n",
       "   72,\n",
       "   198,\n",
       "   4,\n",
       "   119,\n",
       "   34,\n",
       "   159,\n",
       "   20,\n",
       "   822,\n",
       "   0,\n",
       "   16,\n",
       "   109,\n",
       "   84,\n",
       "   34,\n",
       "   0,\n",
       "   35,\n",
       "   324,\n",
       "   47,\n",
       "   180,\n",
       "   245,\n",
       "   272,\n",
       "   0,\n",
       "   273,\n",
       "   144,\n",
       "   7,\n",
       "   83,\n",
       "   193,\n",
       "   64,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   10,\n",
       "   10,\n",
       "   172,\n",
       "   27,\n",
       "   83,\n",
       "   83,\n",
       "   83,\n",
       "   83,\n",
       "   70,\n",
       "   517,\n",
       "   3,\n",
       "   295,\n",
       "   91,\n",
       "   40,\n",
       "   54,\n",
       "   23,\n",
       "   26,\n",
       "   20,\n",
       "   65,\n",
       "   56,\n",
       "   36,\n",
       "   7,\n",
       "   12,\n",
       "   115,\n",
       "   50,\n",
       "   943,\n",
       "   9,\n",
       "   44,\n",
       "   77,\n",
       "   10,\n",
       "   233,\n",
       "   11,\n",
       "   11,\n",
       "   26,\n",
       "   244,\n",
       "   244,\n",
       "   18,\n",
       "   408,\n",
       "   19,\n",
       "   107,\n",
       "   88,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   106,\n",
       "   14,\n",
       "   192,\n",
       "   192,\n",
       "   249,\n",
       "   0,\n",
       "   43,\n",
       "   43,\n",
       "   57,\n",
       "   6,\n",
       "   6,\n",
       "   35,\n",
       "   20,\n",
       "   23,\n",
       "   1,\n",
       "   231,\n",
       "   41,\n",
       "   334,\n",
       "   0,\n",
       "   101,\n",
       "   79,\n",
       "   772,\n",
       "   265,\n",
       "   226,\n",
       "   211,\n",
       "   40,\n",
       "   29,\n",
       "   788,\n",
       "   346,\n",
       "   287,\n",
       "   174,\n",
       "   227,\n",
       "   56,\n",
       "   180,\n",
       "   28,\n",
       "   464,\n",
       "   2,\n",
       "   64,\n",
       "   254,\n",
       "   44,\n",
       "   1,\n",
       "   109,\n",
       "   130,\n",
       "   4,\n",
       "   156,\n",
       "   132,\n",
       "   132,\n",
       "   6,\n",
       "   1692,\n",
       "   106,\n",
       "   12,\n",
       "   230,\n",
       "   25,\n",
       "   19,\n",
       "   19,\n",
       "   0,\n",
       "   4,\n",
       "   40,\n",
       "   7,\n",
       "   587,\n",
       "   36,\n",
       "   45,\n",
       "   45,\n",
       "   45,\n",
       "   45,\n",
       "   1,\n",
       "   28,\n",
       "   17,\n",
       "   160,\n",
       "   249,\n",
       "   65,\n",
       "   141,\n",
       "   51,\n",
       "   323,\n",
       "   323,\n",
       "   171,\n",
       "   98,\n",
       "   6,\n",
       "   15,\n",
       "   29,\n",
       "   73,\n",
       "   5,\n",
       "   21,\n",
       "   0,\n",
       "   30,\n",
       "   19,\n",
       "   150,\n",
       "   111,\n",
       "   287,\n",
       "   2,\n",
       "   41,\n",
       "   3,\n",
       "   8,\n",
       "   5,\n",
       "   249,\n",
       "   22,\n",
       "   353,\n",
       "   0,\n",
       "   265,\n",
       "   0,\n",
       "   10,\n",
       "   10,\n",
       "   203,\n",
       "   78,\n",
       "   18,\n",
       "   549,\n",
       "   44,\n",
       "   461,\n",
       "   13,\n",
       "   58,\n",
       "   35,\n",
       "   146,\n",
       "   272,\n",
       "   119,\n",
       "   27,\n",
       "   288,\n",
       "   7,\n",
       "   1,\n",
       "   26,\n",
       "   228,\n",
       "   53,\n",
       "   154,\n",
       "   68,\n",
       "   4,\n",
       "   76,\n",
       "   400,\n",
       "   28,\n",
       "   28,\n",
       "   51,\n",
       "   143,\n",
       "   12,\n",
       "   13,\n",
       "   120,\n",
       "   317,\n",
       "   317,\n",
       "   317,\n",
       "   217,\n",
       "   217,\n",
       "   325,\n",
       "   192,\n",
       "   623,\n",
       "   11,\n",
       "   13,\n",
       "   33,\n",
       "   141,\n",
       "   286,\n",
       "   239,\n",
       "   7,\n",
       "   51,\n",
       "   58,\n",
       "   279,\n",
       "   7,\n",
       "   45,\n",
       "   32,\n",
       "   2,\n",
       "   10,\n",
       "   1,\n",
       "   10,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   27,\n",
       "   279,\n",
       "   186,\n",
       "   89,\n",
       "   4,\n",
       "   61,\n",
       "   225,\n",
       "   98,\n",
       "   204,\n",
       "   81,\n",
       "   16,\n",
       "   65,\n",
       "   33,\n",
       "   129,\n",
       "   54,\n",
       "   328,\n",
       "   227,\n",
       "   1219,\n",
       "   14,\n",
       "   263,\n",
       "   11,\n",
       "   83,\n",
       "   0,\n",
       "   16,\n",
       "   28,\n",
       "   127,\n",
       "   127,\n",
       "   14,\n",
       "   187,\n",
       "   0,\n",
       "   21,\n",
       "   150,\n",
       "   32,\n",
       "   43,\n",
       "   18,\n",
       "   10,\n",
       "   387,\n",
       "   392,\n",
       "   133,\n",
       "   94,\n",
       "   199,\n",
       "   43,\n",
       "   154,\n",
       "   154,\n",
       "   200,\n",
       "   166,\n",
       "   66,\n",
       "   134,\n",
       "   12,\n",
       "   20,\n",
       "   52,\n",
       "   45,\n",
       "   118,\n",
       "   40,\n",
       "   76,\n",
       "   51,\n",
       "   139,\n",
       "   99,\n",
       "   29,\n",
       "   29,\n",
       "   7]},\n",
       " 'Signal Delay': [1,\n",
       "  1,\n",
       "  19,\n",
       "  4,\n",
       "  42,\n",
       "  1,\n",
       "  1,\n",
       "  18,\n",
       "  4,\n",
       "  41,\n",
       "  1,\n",
       "  1,\n",
       "  45,\n",
       "  12,\n",
       "  62,\n",
       "  1,\n",
       "  19,\n",
       "  2,\n",
       "  12,\n",
       "  1,\n",
       "  22,\n",
       "  1,\n",
       "  1,\n",
       "  18,\n",
       "  30,\n",
       "  3,\n",
       "  1,\n",
       "  33,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  14,\n",
       "  77,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  45,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  92,\n",
       "  1,\n",
       "  11,\n",
       "  2,\n",
       "  93,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  30,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  34,\n",
       "  2,\n",
       "  2,\n",
       "  14,\n",
       "  1,\n",
       "  32,\n",
       "  1,\n",
       "  1,\n",
       "  21,\n",
       "  1,\n",
       "  1,\n",
       "  19,\n",
       "  19,\n",
       "  68,\n",
       "  4,\n",
       "  48,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  17,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  20,\n",
       "  7,\n",
       "  1,\n",
       "  40,\n",
       "  20,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  132,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  55,\n",
       "  1,\n",
       "  8,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  25,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  84,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  13,\n",
       "  1,\n",
       "  18,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  108,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  35,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  21,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  80,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  73,\n",
       "  19,\n",
       "  47,\n",
       "  34,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  13,\n",
       "  30,\n",
       "  1,\n",
       "  2,\n",
       "  7,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  93,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  11,\n",
       "  1,\n",
       "  49,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  24,\n",
       "  1,\n",
       "  4,\n",
       "  191,\n",
       "  6,\n",
       "  6,\n",
       "  10,\n",
       "  47,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  28,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  24,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  21,\n",
       "  1,\n",
       "  1,\n",
       "  42,\n",
       "  52,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  65,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  35,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  67,\n",
       "  14,\n",
       "  100,\n",
       "  2,\n",
       "  5,\n",
       "  18,\n",
       "  11,\n",
       "  1,\n",
       "  1,\n",
       "  55,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  10,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  98,\n",
       "  6,\n",
       "  4,\n",
       "  24,\n",
       "  41,\n",
       "  11,\n",
       "  122,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  42,\n",
       "  1,\n",
       "  1,\n",
       "  106,\n",
       "  152,\n",
       "  1,\n",
       "  47,\n",
       "  1,\n",
       "  117,\n",
       "  147,\n",
       "  1,\n",
       "  2,\n",
       "  65,\n",
       "  80,\n",
       "  51,\n",
       "  10,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  11,\n",
       "  33,\n",
       "  1,\n",
       "  39,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  10,\n",
       "  1,\n",
       "  19,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  126,\n",
       "  4,\n",
       "  3,\n",
       "  67,\n",
       "  71,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  39,\n",
       "  157,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  18,\n",
       "  1,\n",
       "  31,\n",
       "  2,\n",
       "  1,\n",
       "  237,\n",
       "  75,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  52,\n",
       "  1,\n",
       "  2,\n",
       "  20,\n",
       "  1,\n",
       "  5,\n",
       "  73,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  31,\n",
       "  98,\n",
       "  26,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  110,\n",
       "  124,\n",
       "  11,\n",
       "  4,\n",
       "  1,\n",
       "  33,\n",
       "  1,\n",
       "  1,\n",
       "  77,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  121,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  23,\n",
       "  3,\n",
       "  1,\n",
       "  52,\n",
       "  11,\n",
       "  1,\n",
       "  2,\n",
       "  33,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  95,\n",
       "  1,\n",
       "  89,\n",
       "  72,\n",
       "  97,\n",
       "  15,\n",
       "  139,\n",
       "  8,\n",
       "  1,\n",
       "  12,\n",
       "  1,\n",
       "  11,\n",
       "  126,\n",
       "  9,\n",
       "  10,\n",
       "  1,\n",
       "  56,\n",
       "  1,\n",
       "  4,\n",
       "  16,\n",
       "  12,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  14,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  35,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  6,\n",
       "  6,\n",
       "  74,\n",
       "  17,\n",
       "  37,\n",
       "  28,\n",
       "  45,\n",
       "  21,\n",
       "  67,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  66,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  7,\n",
       "  13,\n",
       "  1,\n",
       "  51,\n",
       "  82,\n",
       "  1,\n",
       "  63,\n",
       "  1,\n",
       "  9,\n",
       "  23,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  86,\n",
       "  2,\n",
       "  110,\n",
       "  4,\n",
       "  58,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  51,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  15,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  42,\n",
       "  22,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  207,\n",
       "  5,\n",
       "  44,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  34,\n",
       "  4,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  15,\n",
       "  1,\n",
       "  14,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  57,\n",
       "  15,\n",
       "  3,\n",
       "  96,\n",
       "  1,\n",
       "  24,\n",
       "  19,\n",
       "  10,\n",
       "  4,\n",
       "  32,\n",
       "  1,\n",
       "  8,\n",
       "  53,\n",
       "  2,\n",
       "  38,\n",
       "  28,\n",
       "  41,\n",
       "  48,\n",
       "  1,\n",
       "  31,\n",
       "  4,\n",
       "  15,\n",
       "  1,\n",
       "  171,\n",
       "  1,\n",
       "  1,\n",
       "  42,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  15,\n",
       "  19,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  39,\n",
       "  1,\n",
       "  1,\n",
       "  13,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  24,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  12,\n",
       "  7,\n",
       "  102,\n",
       "  1,\n",
       "  79,\n",
       "  1,\n",
       "  10,\n",
       "  9,\n",
       "  1,\n",
       "  70,\n",
       "  10,\n",
       "  3,\n",
       "  15,\n",
       "  77,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  8,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  48,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  58,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  107,\n",
       "  48,\n",
       "  1,\n",
       "  1,\n",
       "  20,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  53,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  23,\n",
       "  72,\n",
       "  84,\n",
       "  1,\n",
       "  139,\n",
       "  192,\n",
       "  17,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  71,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  5,\n",
       "  1,\n",
       "  63,\n",
       "  23,\n",
       "  10,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  49,\n",
       "  66,\n",
       "  84,\n",
       "  1,\n",
       "  1,\n",
       "  26,\n",
       "  1,\n",
       "  11,\n",
       "  175,\n",
       "  9,\n",
       "  14,\n",
       "  3,\n",
       "  14,\n",
       "  1,\n",
       "  18,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  23,\n",
       "  16,\n",
       "  3,\n",
       "  50,\n",
       "  59,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  61,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  60,\n",
       "  34,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  54,\n",
       "  11,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  13,\n",
       "  14,\n",
       "  28,\n",
       "  70,\n",
       "  11,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  6,\n",
       "  1,\n",
       "  5,\n",
       "  64,\n",
       "  107,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  89,\n",
       "  1,\n",
       "  1,\n",
       "  20,\n",
       "  1,\n",
       "  1,\n",
       "  64,\n",
       "  6,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  11,\n",
       "  170,\n",
       "  1,\n",
       "  19,\n",
       "  1,\n",
       "  1,\n",
       "  40,\n",
       "  33,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  63,\n",
       "  1,\n",
       "  15,\n",
       "  1,\n",
       "  1,\n",
       "  89,\n",
       "  1,\n",
       "  59,\n",
       "  83,\n",
       "  55,\n",
       "  40,\n",
       "  93,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  27,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  18,\n",
       "  4,\n",
       "  14,\n",
       "  152,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  32,\n",
       "  1,\n",
       "  1,\n",
       "  17,\n",
       "  1,\n",
       "  1,\n",
       "  16,\n",
       "  1,\n",
       "  126,\n",
       "  29,\n",
       "  67,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  11,\n",
       "  7,\n",
       "  1,\n",
       "  32,\n",
       "  29,\n",
       "  1,\n",
       "  14,\n",
       "  28,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  19,\n",
       "  8,\n",
       "  26,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  18,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  10,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  16,\n",
       "  6,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  10,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  8,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  41,\n",
       "  1,\n",
       "  65,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  18,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  134,\n",
       "  95,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  18,\n",
       "  83,\n",
       "  1,\n",
       "  22,\n",
       "  1,\n",
       "  22,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  6,\n",
       "  31,\n",
       "  8,\n",
       "  3,\n",
       "  1,\n",
       "  6,\n",
       "  39,\n",
       "  1,\n",
       "  1,\n",
       "  139,\n",
       "  168,\n",
       "  23,\n",
       "  2,\n",
       "  89,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  10,\n",
       "  125,\n",
       "  52,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  97,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  1,\n",
       "  22,\n",
       "  70,\n",
       "  79,\n",
       "  31,\n",
       "  1,\n",
       "  31,\n",
       "  1,\n",
       "  1,\n",
       "  54,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  22,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  44,\n",
       "  1,\n",
       "  17,\n",
       "  1,\n",
       "  1,\n",
       "  12,\n",
       "  1,\n",
       "  8,\n",
       "  1,\n",
       "  4,\n",
       "  11,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  153,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  53,\n",
       "  18,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  152,\n",
       "  92,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  12,\n",
       "  1,\n",
       "  13,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  37,\n",
       "  158,\n",
       "  1,\n",
       "  27,\n",
       "  1,\n",
       "  5,\n",
       "  7,\n",
       "  1,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  ...]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_delay = []\n",
    "for i in signal_delay:\n",
    "    sd_delay.append(int(i))\n",
    "\n",
    "#files = [long_sl_hit, long_tp_hit, short_sl_hit, short_tp_hit]\n",
    "import json\n",
    "data = {\"Long\" : {\"long_sl_hit\" : long_sl_hit,\n",
    "                \"long_tp_hit\" : long_tp_hit },\n",
    "       \"Short\" : {\"short_sl_hit\" : short_sl_hit,\n",
    "                 \"short_tp_hit\" : short_tp_hit},\n",
    "        \"Signal Delay\" : sd_delay\n",
    "       }\n",
    "\n",
    "with open(f\"{symbol} Backtest Metrics.json\", \"w\") as f:\n",
    "    json.dump(data,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948b385-b21e-4660-ba7a-688b1a0d0048",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "length = [len(short_tp_hit), len(short_sl_hit)]\n",
    "labels = [\"TP Hit\", \"SL Hit\"]\n",
    "\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "from matplotlib import gridspec\n",
    "gs = gridspec.GridSpec(2,2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "ax3 = fig.add_subplot(gs[1,0])\n",
    "ax4 = fig.add_subplot(gs[1,1])\n",
    "\n",
    "ax1.set_title(f\"Short Trade Summary for {symbol}\")\n",
    "\n",
    "length = [len(short_tp_hit), len(short_sl_hit)]\n",
    "labels = [\"TP Hit\", \"SL Hit\"]\n",
    "bars = ax1.bar(labels, length, color = [\"green\",\"red\"], alpha = 0.6)\n",
    "ax1.bar_label(bars, padding = 1)\n",
    "\n",
    "ax2.set_title(f\"Long Trade Summary for {symbol}\")\n",
    "length = [len(long_tp_hit), len(long_sl_hit)]\n",
    "labels = [\"TP Hit\", \"SL Hit\"]\n",
    "bars = ax2.bar(labels, length, color = [\"green\",\"red\"], alpha = 0.6)\n",
    "ax2.bar_label(bars, padding = 1)\n",
    "\n",
    "ax3.set_title(f\"Long Trade Summary for {symbol}\")\n",
    "length = [(len(short_tp_hit) + len(long_tp_hit))/(len(longs) + len(shorts)), (len(short_sl_hit) + len(long_sl_hit))/ len(longs) + len(shorts)]\n",
    "labels = [\"TP Hit\", \"SL Hit\"]\n",
    "bars = ax3.bar(labels, length, color = [\"green\",\"red\"], alpha = 0.6)\n",
    "ax3.bar_label(bars, padding = 1)\n",
    "\n",
    "profit = np.array(cum).reshape(-1,1)\n",
    "profit = profit * 500\n",
    "profit = profit.cumsum()\n",
    "starting_balance = 200000\n",
    "equity = starting_balance + profit\n",
    "numbers = np.arange(0, len(equity))\n",
    "ax4.set_title(f\"Running equity with start.equity of {starting_balance}\")\n",
    "ax4.plot(numbers, equity, color= \"red\", alpha = 0.8)\n",
    "#plt.text(f\"No. of trades taken = {len(shorts) + len(longs)}\")\n",
    "ax4.scatter(numbers[-1], equity[-1], color=\"black\", marker=\"*\", label = f\"Last equity value = {equity[-1]}\")\n",
    "ax4.grid()\n",
    "ax4.legend()\n",
    "\n",
    "plt.savefig(f\"MV Strategy Summary for {symbol}.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0558ac8-1056-4b49-bb16-fa55a41b9714",
   "metadata": {},
   "source": [
    "### Total Summary Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626a2f1-dfa5-4ef9-bcc8-a59e39842185",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "total_long = len(total_long_tp) +  len(total_long_sl)\n",
    "total_short = len(total_short_sl) +  len(total_short_tp)\n",
    "total_trades = total_long + total_short\n",
    "total_tp = len(total_long_tp) + len(total_short_tp)\n",
    "total_sl = len(total_long_sl) + len(total_short_sl)\n",
    "\n",
    "total_win_pc = round(100*total_tp/total_trades,2)\n",
    "total_loss_pc = round(100*total_sl/total_trades,2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "\n",
    "gs = gridspec.GridSpec(2,2)\n",
    "fig = plt.figure(figsize = (16,12))\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "ax3 = fig.add_subplot(gs[1,0])\n",
    "ax4 = fig.add_subplot(gs[1,1])\n",
    "\n",
    "ax1.set_title(f\"MV Logic Summary - Across 9 Instruments {9*90000} Bars\")\n",
    "\n",
    "labels = [\"Win %\", \"Loss %\"]\n",
    "length = [total_win_pc, total_loss_pc]\n",
    "bars = ax1.bar(labels, length, color = [\"blue\", \"red\"], alpha = 0.6)\n",
    "ax1.bar_label(bars, padding = 1)\n",
    "ax1.text(0.7,60, f\"Entry Rate = 100%\", bbox=dict(facecolor='white', alpha=0.5))\n",
    "#ax1.grid()\n",
    "\n",
    "sd = signal_delay\n",
    "sd = np.array(sd)\n",
    "sd_realized = sd*5\n",
    "\n",
    "## Plot normal distribution graph\n",
    "\n",
    "mu, sigma = sd_realized.mean(), sd_realized.std()\n",
    "x = np.linspace(sd_realized.min(), sd_realized.max(), 100 )\n",
    "mu, loc, sigma = skewnorm.fit(sd_realized)\n",
    "skew_pdf = skewnorm.pdf(x, mu, loc, sigma)\n",
    "\n",
    "ax2.set_title(\"Skewnormal Distrubution of Signal Delay (mins)\")\n",
    "ax2.plot(x, skew_pdf, color = \"red\", alpha = 0.5)\n",
    "ax2.hist(sd_realized, bins = 200, density=True)\n",
    "ax2.axvline(loc, label=f\"Avg signal delay = {round(loc,2)} mins \\n\\nTotal Signals = {total_trades}\", color = \"red\")\n",
    "ax2.set_xlabel(\"Time in Minutes\")\n",
    "#ax2.text(1000, 0.09, f\"Total Signals = {total_trades}\", bbox=dict(facecolor='white', alpha=0.5))\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "cumul = total_cum[0:len(total_cum) - 2]\n",
    "cumul = np.array(cumul).reshape(-1,4)\n",
    "profit = cumul.sum(axis = 1)\n",
    "profit = profit * 500\n",
    "profit = profit.cumsum()\n",
    "starting_balance = 200000\n",
    "equity = starting_balance + profit\n",
    "numbers = np.arange(0, len(equity))\n",
    "\n",
    "ax3.set_title(f\"Running equity with start.equity of {starting_balance}\")\n",
    "ax3.plot(numbers, equity, color= \"red\", alpha = 0.8)\n",
    "#plt.text(f\"No. of trades taken = {len(shorts) + len(longs)}\")\n",
    "ax3.scatter(numbers[-1], equity[-1], color=\"black\", marker=\"*\", label = f\"Last equity value = {equity[-1]}\")\n",
    "ax3.grid()\n",
    "ax3.set_xlabel(\"Days\")\n",
    "ax3.legend()\n",
    "\n",
    "### ax4\n",
    "\n",
    "cumul = total_cum[0:len(total_cum) - 2]\n",
    "cumul = np.array(cumul).reshape(-1,4)\n",
    "profit = cumul.sum(axis = 1)\n",
    "runs = []\n",
    "start_balance = 200000\n",
    "risk = 500\n",
    "while len(runs) != 1000:\n",
    "    cumul = total_cum[0:len(total_cum) - 2]\n",
    "    cumul = np.random.permutation(cumul)\n",
    "    cumul = np.array(cumul).reshape(-1,4)\n",
    "    profit = cumul.sum(axis = 1) * 500\n",
    "    equity_run = start_balance + profit.cumsum()\n",
    "    runs.append(equity_run)\n",
    "print(f\"Monte Carlo Success, len(runs) = {len(runs)}\")\n",
    "\n",
    "cumul = total_cum[0:len(total_cum) - 2]\n",
    "cumul = np.array(cumul).reshape(-1,4)\n",
    "profit = cumul.sum(axis = 1)\n",
    "runs = []\n",
    "start_balance = 200000\n",
    "risk = 500\n",
    "while len(runs) != 1000:\n",
    "    cumul = total_cum[0:len(total_cum) - 2]\n",
    "    cumul = np.random.permutation(cumul)\n",
    "    cumul = np.array(cumul).reshape(-1,4)\n",
    "    profit = cumul.sum(axis = 1) * 500\n",
    "    equity_run = start_balance + profit.cumsum()\n",
    "    runs.append(equity_run)\n",
    "print(f\"Monte Carlo Success, len(runs) = {len(runs)}\")\n",
    "\n",
    "drawdown_list = []\n",
    "for equity_run in runs:\n",
    "    numbers = np.arange(len(equity_run))\n",
    "    drawdown = -100*(start_balance - equity_run.min())/start_balance\n",
    "    if drawdown < 0 :\n",
    "        drawdown_list.append(drawdown)\n",
    "print(\"Drawdown Successfully Calculated\")\n",
    "dd = np.array(drawdown_list)\n",
    "j = np.linspace(dd.min(), dd.max(), 500)\n",
    "\n",
    "from scipy.stats import jf_skew_t\n",
    "mu, loc, sigma, k = jf_skew_t.fit(dd)\n",
    "gamma_pdf = jf_skew_t.pdf(j, mu, loc, sigma,k)\n",
    "ax4.set_title(\"Monte Carlo Sim 1000 Trials - Skewed-T Dist. of VaR% with MV\")\n",
    "ax4.plot(j, gamma_pdf, color = \"red\", alpha = 1)\n",
    "ax4.hist(dd, bins = 500, density = True, color=\"blue\", alpha = 1 )\n",
    "fifty_percentile = round(jf_skew_t.ppf(0.8, mu, loc, sigma, k),4)\n",
    "\n",
    "ax4.axvline(fifty_percentile, label=f\"Avg DD/Risk = {fifty_percentile}%\", color = \"red\")\n",
    "ninety_percentile = round(jf_skew_t.ppf(0.1, mu, loc, sigma, k),4)\n",
    "print(ninety_percentile)\n",
    "ax4.axvline(ninety_percentile, label=f\"90th Percentile = {ninety_percentile}%\", color = \"red\", linestyle = \"--\", alpha = 0.8)\n",
    "\n",
    "ax4.set_xlabel(\"DD Risk %\")\n",
    "ax4.grid()\n",
    "\n",
    "ax4.legend()  \n",
    "plt.savefig(\"MV Logic Summary Across All Instruments.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03720bd7-79e8-4c15-ad2b-1e8444caf8ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "jf_skew_t.fit(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c2766c-f933-46a4-8741-cfb7fdd46898",
   "metadata": {},
   "source": [
    "### Time to TP/SL Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d103b8d-2da4-4e84-bfba-90b27b55a21a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,12))\n",
    "gs = gridspec.GridSpec(2,2)\n",
    "ax5 = fig.add_subplot(gs[0,0])\n",
    "ax6 = fig.add_subplot(gs[0,1])\n",
    "ax7 = fig.add_subplot(gs[1,0])\n",
    "ax8 = fig.add_subplot(gs[1,1])\n",
    "\n",
    "\n",
    "\n",
    "weibull_plot(total_long_tp)\n",
    "ax5.set_title(\"Longs - Time to TP\")\n",
    "ax5.plot(x, skew_pdf, color = \"red\", alpha = 1)\n",
    "ax5.hist(time_to_tp_long, bins = 200, density= True, color = \"blue\", alpha = 0.8)\n",
    "ax5.axvline(round(loc,2), label = f\"Avg Time = {5*round(loc,2)} minutes\", color = \"red\", alpha = 0.6)\n",
    "ax5.axvline(round(ninety_percentile,2), label = f\"90th Percentile = {5*round(ninety_percentile,2)} minutes\", color = \"red\", alpha = 0.6, linestyle = \"--\")\n",
    "ax5.set_xlabel(\"Bars\")\n",
    "ax5.legend()\n",
    "ax5.grid()\n",
    "\n",
    "\n",
    "weibull_plot(total_long_sl)\n",
    "ax6.set_title(\"Longs - Time to SL\")\n",
    "ax6.plot(x, skew_pdf, color = \"red\", alpha = 1)\n",
    "ax6.hist(total_long_sl, bins = 200, density= True, color = \"blue\", alpha = 0.8)\n",
    "ax6.axvline(round(loc,2), label = f\"Avg Time = {5*round(loc,2)} minutes\", color = \"red\", alpha = 0.6)\n",
    "ax6.axvline(round(ninety_percentile,2), label = f\"90th Percentile = {5*round(ninety_percentile,2)} minutes\", color = \"red\", alpha = 0.6, linestyle = \"--\")\n",
    "ax6.set_xlabel(\"Bars\")\n",
    "ax6.legend()\n",
    "ax6.grid()\n",
    "\n",
    "weibull_plot(total_short_tp)\n",
    "ax7.set_title(\"Short - Time to TP\")\n",
    "ax7.plot(x, skew_pdf, color = \"red\", alpha = 1)\n",
    "ax7.hist(total_short_tp, bins = 200, density= True, color = \"blue\", alpha = 0.8)\n",
    "ax7.axvline(round(loc,2), label = f\"Avg Time = {5*round(loc,2)} minutes\", color = \"red\", alpha = 0.6)\n",
    "ax7.axvline(round(ninety_percentile,2), label = f\"90th Percentile = {5*round(ninety_percentile,2)} minutes\", color = \"red\", alpha = 0.6, linestyle = \"--\")\n",
    "ax7.set_xlabel(\"Bars\")\n",
    "ax7.legend()\n",
    "ax7.grid()\n",
    "\n",
    "weibull_plot(total_short_sl)\n",
    "ax8.set_title(\"Short - Time to SL\")\n",
    "ax8.plot(x, skew_pdf, color = \"red\", alpha = 1)\n",
    "ax8.hist(total_short_sl, bins = 200, density= True, color = \"blue\", alpha = 0.8)\n",
    "ax8.axvline(round(loc,2), label = f\"Avg Time = {5*round(loc,2)} minutes\", color = \"red\", alpha = 0.6)\n",
    "ax8.axvline(round(ninety_percentile,2), label = f\"90th Percentile = {5*round(ninety_percentile,2)} minutes\", color = \"red\", alpha = 0.6, linestyle = \"--\")\n",
    "ax8.set_xlabel(\"Bars\")\n",
    "ax8.legend()\n",
    "ax8.grid()\n",
    "\n",
    "plt.savefig(\"Time to TP-SL.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc050c-4417-40db-ab9b-8288cfbb06c0",
   "metadata": {},
   "source": [
    "### Signal Delay Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec576d-571c-4301-9ca4-043e0048a5a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Plotting signal delay\n",
    "\n",
    "sd = signal_delay\n",
    "sd = np.array(sd)\n",
    "sd_realized = sd*5\n",
    "\n",
    "## Plot normal distribution graph\n",
    "\n",
    "mu, sigma = sd_realized.mean(), sd_realized.std()\n",
    "x = np.linspace(sd_realized.min(), sd_realized.max(), 50 )\n",
    "mu, loc, sigma = skewnorm.fit(sd_realized)\n",
    "skew_pdf = skewnorm.pdf(x, mu, loc, sigma)\n",
    "plt.title(\"Normal Distrubution of Signal Delay (mins)\")\n",
    "plt.plot(x, skew_pdf, color = \"red\", alpha = 0.5)\n",
    "plt.hist(sd_realized, bins = 50, density=True)\n",
    "plt.axvline(loc, label=f\"Avg signal delay = {round(loc,2)} mins\", color = \"red\")\n",
    "plt.xlabel(\"Time in Minutes\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff592ff1-45b5-4949-9348-28622464e236",
   "metadata": {},
   "source": [
    "### Running Equity Based on Results - Vectorised (4 trades per day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cec60b-0065-4c0f-95da-daab75fae04c",
   "metadata": {},
   "source": [
    "#### Monte-Carlo Sim - 1000 Trials (VaR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ccc486-4854-4504-8299-9f30adbebaa3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cumul = total_cum[0:len(total_cum) - 2]\n",
    "cumul = np.array(cumul).reshape(-1,4)\n",
    "profit = cumul.sum(axis = 1)\n",
    "runs = []\n",
    "start_balance = 200000\n",
    "risk = 500\n",
    "while len(runs) != 1000:\n",
    "    cumul = total_cum[0:len(total_cum) - 2]\n",
    "    cumul = np.random.permutation(cumul)\n",
    "    cumul = np.array(cumul).reshape(-1,4)\n",
    "    profit = cumul.sum(axis = 1) * 500\n",
    "    equity_run = start_balance + profit.cumsum()\n",
    "    runs.append(equity_run)\n",
    "print(f\"Monte Carlo Success, len(runs) = {len(runs)}\")\n",
    "\n",
    "drawdown_list = []\n",
    "for equity_run in runs:\n",
    "    numbers = np.arange(len(equity_run))\n",
    "    drawdown = -100*(start_balance - equity_run.min())/start_balance\n",
    "    if drawdown < 0 :\n",
    "        drawdown_list.append(drawdown)\n",
    "print(\"Drawdown Successfully Calculated\")\n",
    "dd = np.array(drawdown_list)\n",
    "j = np.linspace(dd.min(), dd.max(), 500)\n",
    "\n",
    "mu, loc, sigma = skewnorm.fit(dd)\n",
    "gamma_pdf = skewnorm.pdf(j, mu, loc, sigma)\n",
    "plt.title(\"Skewnormal Dist. of Risk% with MV\")\n",
    "plt.plot(j, gamma_pdf, color = \"red\", alpha = 0.8)\n",
    "plt.hist(dd, bins = 500, density = True, color=\"blue\", alpha = 1 )\n",
    "plt.axvline(round(loc,4), label=f\"Avg DD/Risk = {round(loc,4)}%\", color = \"red\")\n",
    "ninety_percentile = round(skewnorm.ppf(0.1, mu, loc, sigma),4)\n",
    "print(ninety_percentile)\n",
    "plt.axvline(ninety_percentile, label=f\"90th Percentile = {ninety_percentile}%\", color = \"red\", linestyle = \"--\", alpha = 0.8)\n",
    "\n",
    "plt.xlabel(\"DD Risk %\")\n",
    "plt.grid()\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bea068-ec6e-41ca-973b-8ac74ddd50fa",
   "metadata": {},
   "source": [
    "#### Cumulative RR of Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cb955-45da-4e50-80a9-310cec6a034b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cumul = total_cum[0:len(total_cum) - 2]\n",
    "cumul = np.array(cumul).reshape(-1,4)\n",
    "profit = cumul.sum(axis = 1)\n",
    "profit = profit * 500\n",
    "profit = profit.cumsum()\n",
    "starting_balance = 200000\n",
    "equity = starting_balance + profit\n",
    "numbers = np.arange(0, len(equity))\n",
    "plt.title(f\"Running equity with start.equity of {starting_balance}\")\n",
    "plt.plot(numbers, equity, color= \"red\", alpha = 0.8)\n",
    "#plt.text(f\"No. of trades taken = {len(shorts) + len(longs)}\")\n",
    "plt.scatter(numbers[-1], equity[-1], color=\"black\", marker=\"*\", label = f\"Last equity value = {equity[-1]}\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Days\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ffea3c-5554-477a-91da-3ed6d5a20230",
   "metadata": {},
   "source": [
    "### Plotting Slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0be79-049f-4bfb-87c9-f3e1ec382e0f",
   "metadata": {},
   "source": [
    "### Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71530b7b-7903-49b8-a9f4-d46cef16a56d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
